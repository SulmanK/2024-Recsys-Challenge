{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2671047-b3da-4686-8a34-f7e63d82e738",
   "metadata": {},
   "source": [
    "Task\n",
    "- Add in other uestions\n",
    "    - Refactor code for the aggregation of timely activity\n",
    "- Fix the plots\n",
    "- Start on EDA\n",
    "    - Each major feature will cover distribution of the feature, readtime/scroll pct, how it relates to the topics selected, and activity distribution.\n",
    "        - We will use histograms, bar plots, box plots, and scatter plots (can look at pie charts too)\n",
    "- Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237298c2-2986-4bba-bcbd-5ff27e361919",
   "metadata": {},
   "source": [
    "Background Information on Dataset: BLAH BLAH BLAH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8cf39e-f468-4ac2-9f59-2eefab32a277",
   "metadata": {},
   "source": [
    "Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4711c74-a01b-4ce7-8a3d-de5a605d13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f05b58-dde3-4d5f-87a2-f20ad71cd62b",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616fa6a4-e47a-4116-82f5-896d6893a00e",
   "metadata": {},
   "source": [
    "Load in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b171de10-39f1-4dad-aed9-d8a179e44fe2",
   "metadata": {},
   "source": [
    "Aside: Let's measure how long it takes to load in our dataset: using pandas and dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5445ae-b902-4ce8-9f7b-717b3b0b4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "df = pd.read_parquet(\"Data/Large/articles.parquet\")\n",
    "profiler.disable()\n",
    "\n",
    "profiler_stats = pstats.Stats(profiler)\n",
    "profiler_stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15aa7e8-ef30-4e1d-908c-9dc597f5bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "df = dd.read_parquet(\"Data/Large/articles.parquet\", engine = \"fastparquet\")\n",
    "profiler.disable()\n",
    "\n",
    "profiler_stats = pstats.Stats(profiler)\n",
    "profiler_stats.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fe4d4a-f8e0-4b9d-a9dd-7b5719a44b6f",
   "metadata": {},
   "source": [
    "Even though the dataframe took 1.464 seconds to load using pandas, dask took 0.054 seconds. This is a huge speedup ~ 27x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59a57c46-4e08-4299-8a69-12d45e274b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in various dataframes\n",
    "## Articles\n",
    "df_art = pd.read_parquet(\"Data/Small/articles.parquet\")\n",
    "\n",
    "## Behaviors\n",
    "df_bev = pd.read_parquet(\"Data/Small/train/behaviors.parquet\")\n",
    "\n",
    "## History\n",
    "df_his = pd.read_parquet(\"Data/Small/train/history.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d447c",
   "metadata": {},
   "source": [
    "Join the data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3cfa16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datatype of column first\n",
    "df_bev['article_ids_clicked'] = df_bev['article_ids_clicked'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eaa9148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join bevhaiors to article\n",
    "df= df_bev.join(df_art.set_index(\"article_id\"), on = \"article_ids_clicked\")\n",
    "\n",
    "# Join bevhaiors to history \n",
    "df= df.join(df_his.set_index(\"user_id\"), on = \"user_id\")\n",
    "\n",
    "# Drop all other dataframes from me\n",
    "df_bev = []\n",
    "df_his = []\n",
    "df_art = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5796b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df.dropna(subset=['article_id'], inplace= True)\n",
    "#df.dropna(subset =['age'], inplace = True)\n",
    "\n",
    "\n",
    "df['article_id'] = df['article_id'].apply(lambda x: int(x))\n",
    "\n",
    "df['article_id']= df['article_id'].astype(np.int64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd2615",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_index_values(groupby_object):\n",
    "    \"\"\"Takes in a clause from a pandas groupby statement and returns X and Y variables used for plotting\"\"\"\n",
    "\n",
    "    index = groupby_object.index\n",
    "    values = groupby_object.values\n",
    "\n",
    "    return index, values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0b195",
   "metadata": {},
   "source": [
    "Lets calculate the unique users for hourly, daily, and day of the week. Let's use a subset of the data until we know our plots are very good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988d669",
   "metadata": {},
   "source": [
    "#### Biggest thing is user engagement : Bigger User Engagement -> More eveneue\n",
    "#### We need to maximize the amount of ads these guys are viewing -> this leads on to them clicking on new articles for ads\n",
    "#### So, let's not make article length too short so that people can maximize their session lengths with a lot of articles!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c8812",
   "metadata": {},
   "source": [
    "## User Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c2e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make subsets for each user_id and then populate the frequency based on that\n",
    "\n",
    "## Get all unique ids in a list\n",
    "\n",
    "unique_user_ids = df['user_id'].unique()[0:1000]\n",
    "\n",
    "# Create dictionaries\n",
    "unique_users_daily_freq = {}\n",
    "unique_users_hourly_freq = {}\n",
    "unique_users_dayofweek_freq = {}\n",
    "unique_users_weekly_freq = {}\n",
    "\n",
    "for id in unique_user_ids:\n",
    "    # Get the subset of that user id\n",
    "    tmp_df = df[df['user_id'] == id]\n",
    "\n",
    "    # Now lets go through each and populate the unique dates, hours and day of the week for each user\n",
    "    dates = []\n",
    "    hours = []\n",
    "    dayofweek = []\n",
    "    week = []\n",
    "    indices = np.array(tmp_df.index)\n",
    "    for i in indices:\n",
    "        tmp_datetime = pd.DatetimeIndex(tmp_df['impression_time_fixed'][i])\n",
    "        tmp_date = tmp_datetime.date\n",
    "        tmp_time = tmp_datetime.time\n",
    "        tmp_dayofweek = tmp_datetime.day_of_week\n",
    "        tmp_week = tmp_datetime.isocalendar().week\n",
    "\n",
    "        for j in tmp_date:\n",
    "            dates.append(j)\n",
    "        \n",
    "        for k in tmp_time:\n",
    "            hours.append(k)\n",
    "        \n",
    "        for l in tmp_dayofweek:\n",
    "            dayofweek.append(l)\n",
    "        \n",
    "        for m in tmp_week:\n",
    "            week.append(m)\n",
    "\n",
    "    # Get rid of duplicate values\n",
    "    unique_dates = list(set(dates))\n",
    "    unique_hours = list(set(hours))\n",
    "    unique_dayofweek = list(set(dayofweek))\n",
    "    unique_week = list(set(week))\n",
    "\n",
    "    # Convert to string\n",
    "    unique_dates = [x.strftime('%m/%d/%Y') for x in unique_dates]\n",
    "    unique_hours = [x.hour for x in unique_hours]\n",
    "\n",
    "\n",
    "    # Populate our unique_user_daily_freq dict\n",
    "    for i in unique_dates:\n",
    "        \n",
    "        if i not in unique_users_daily_freq:\n",
    "            unique_users_daily_freq[i] = 1\n",
    "        else:\n",
    "            unique_users_daily_freq[i] +=1\n",
    "        \n",
    "\n",
    "    # Populate hourly activity\n",
    "    for j in unique_hours:\n",
    "\n",
    "        if j not in unique_users_hourly_freq:\n",
    "            unique_users_hourly_freq[j] = 1\n",
    "        else:\n",
    "            unique_users_hourly_freq[j] +=1\n",
    "\n",
    "    # Populate dayofweeka activity\n",
    "    for k in unique_dayofweek:\n",
    "\n",
    "        if k not in unique_users_dayofweek_freq:\n",
    "            unique_users_dayofweek_freq[k] = 1\n",
    "        else:\n",
    "            unique_users_dayofweek_freq[k] +=1\n",
    "    \n",
    "\n",
    "    # Populate dayofweeka activity\n",
    "    for l in unique_week:\n",
    "\n",
    "        if l not in unique_users_weekly_freq:\n",
    "            unique_users_weekly_freq[l] = 1\n",
    "        else:\n",
    "            unique_users_weekly_freq[l] +=1\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ef394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the daily user activity look like?\n",
    "unique_users_daily_freq = dict(sorted(unique_users_daily_freq.items()))\n",
    "\n",
    "indices = [x for x in unique_users_daily_freq.keys()]\n",
    "values = [x for x in unique_users_daily_freq.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x = indices, y = values,\n",
    "                         mode = 'lines+markers'\n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a681f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the hourly user activity look like?\n",
    "indices = [x for x in unique_users_hourly_freq.keys()]\n",
    "values = [x for x in unique_users_hourly_freq.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x = indices, y = values,\n",
    "                         mode = 'markers'\n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the weekly user activity look like?\n",
    "indices = [x for x in unique_users_weekly_freq.keys()]\n",
    "values = [x for x in unique_users_weekly_freq.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x = indices, y = values,\n",
    "                         mode = 'markers'\n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the weekly user activity look like?\n",
    "indices = [x for x in unique_users_dayofweek_freq.keys()]\n",
    "values = [x for x in unique_users_dayofweek_freq.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x = indices, y = values,\n",
    "                         mode = 'markers'\n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668d320",
   "metadata": {},
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ef1f1",
   "metadata": {},
   "source": [
    "Daily User growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d61b4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = df['user_id'].unique()\n",
    "\n",
    "# Create dictionaries\n",
    "unique_users_daily_growth_freq= {}\n",
    "unique_users_hourly_freq = {}\n",
    "unique_users_dayofweek_freq = {}\n",
    "unique_users_weekly_freq = {}\n",
    "\n",
    "for id in unique_user_ids:\n",
    "    # Get the subset of that user id\n",
    "    tmp_df = df[df['user_id'] == id]\n",
    "    first_index = tmp_df['impression_time_fixed'].index[0]\n",
    "    tmp_datetime = pd.DatetimeIndex(tmp_df['impression_time_fixed'][first_index])\n",
    "    tmp_date = tmp_datetime[0].date()\n",
    "    join_date = tmp_date.strftime('%m/%d/%Y')\n",
    "    #join_date = join_date.strftime('%m/%d/%Y')\n",
    "    \n",
    "    if join_date not in unique_users_daily_growth_freq:\n",
    "        unique_users_daily_growth_freq[join_date] = 1\n",
    "    else:\n",
    "        unique_users_daily_growth_freq[join_date] +=1\n",
    "    \n",
    "unique_users_daily_growth_freq = dict(sorted(unique_users_daily_growth_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bafa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [x for x in unique_users_daily_growth_freq.keys()]\n",
    "values = [x for x in unique_users_daily_growth_freq.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Bar(x = indices, y = values,\n",
    "                         \n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6f358",
   "metadata": {},
   "source": [
    "### Average readtime per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average readtime per user\n",
    "avg_read_times = df.groupby(by =  'user_id')['read_time'].mean()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=avg_read_times))\n",
    "\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.55)\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4424d9e",
   "metadata": {},
   "source": [
    "### Average scroll percentage per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d400e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average scroll time across each user\n",
    "## Average readtime per user\n",
    "avg_scroll_percentage = df.groupby(by = 'user_id')['scroll_percentage'].mean()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=avg_scroll_percentage))\n",
    "\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.55)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812afcd3",
   "metadata": {},
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeee20c",
   "metadata": {},
   "source": [
    "Daily Active Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7868e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique sessions per day\n",
    "tmp_df = df\n",
    "tmp_df['impression_time'] = tmp_df['impression_time'].apply(lambda x: x.strftime('%m/%d/%Y'))\n",
    "\n",
    "\n",
    "unique_session_dates= tmp_df['impression_time'].unique()\n",
    "unique_sessions_per_day = tmp_df.groupby(by = 'session_id')['impression_time'].min()\n",
    "unique_sessions_daily_growth = {k:0 for k in unique_sessions_per_day}\n",
    "\n",
    "\n",
    "for x in unique_sessions_per_day.values:\n",
    "    unique_sessions_daily_growth[x] +=1\n",
    "\n",
    "unique_sessions_daily_growth = dict(sorted(unique_sessions_daily_growth.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44db7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [x for x in unique_sessions_daily_growth.keys()]\n",
    "values = [x for x in unique_sessions_daily_growth.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Bar(x = indices, y = values,\n",
    "                         \n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76c067",
   "metadata": {},
   "source": [
    "### Average readtime per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af644351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each session, what was the average readtimes\n",
    "\n",
    "## Average readtime per session\n",
    "avg_read_times = df.groupby(by ='session_id')['read_time'].mean()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=avg_read_times))\n",
    "\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.55)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d99ce7",
   "metadata": {},
   "source": [
    "Average scroll percentage per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each session, what was the average scroll time\n",
    "\n",
    "# Distribution blot histogram (bin it)\n",
    "df.groupby(by= 'session_id')['scroll_percentage'].mean()\n",
    "\n",
    "## Average readtime per user\n",
    "avg_scroll_pct = df.groupby(by ='session_id')['scroll_percentage'].mean()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=avg_scroll_pct))\n",
    "\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.55)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae85ec3",
   "metadata": {},
   "source": [
    "## Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get unique_user_ids topics\n",
    "\n",
    "## Get all unique ids in a list\n",
    "\n",
    "unique_user_ids = df['user_id'].values[0:1000]\n",
    "\n",
    "# Create dictionaries\n",
    "unique_users_topics_freq= {}\n",
    "unique_topic_scroll_freq = {}\n",
    "unique_topic_read_freq = {}\n",
    "\n",
    "for id in unique_user_ids:\n",
    "    # Get the subset of that user id\n",
    "    tmp_df = df[df['user_id'] == id]\n",
    "\n",
    "    # Now lets go through each topic\n",
    "    indices = np.array(tmp_df.index)\n",
    "    for i in indices:\n",
    "        tmp_topics = tmp_df['topics'][i]\n",
    "        tmp_scroll = tmp_df['scroll_percentage'][i]\n",
    "        tmp_read = tmp_df['read_time'][i]\n",
    "\n",
    "        topics = [x for x in tmp_topics]\n",
    "        scroll = [tmp_scroll]\n",
    "        read = [tmp_read]\n",
    "\n",
    "            \n",
    "    # Find the average scroll percentages across each topic  (Can be related to whether a topic doesnt require too much reading has visualizations)\n",
    "\n",
    "    ## Group by user ID\n",
    "    ### Look at article_id for whichever topics the article is included in add that readtime and scroll percentage\n",
    "        tmp_dict = {k:v for k,v in zip(topics, scroll)}\n",
    "\n",
    "        for k,v in zip(tmp_dict.keys(), tmp_dict.values()):\n",
    "\n",
    "            if (k in unique_topic_scroll_freq.keys()):\n",
    "                tmp_array= np.append(unique_topic_scroll_freq[k],v)\n",
    "                unique_topic_scroll_freq[k] = tmp_array\n",
    "            if (k not in unique_topic_scroll_freq.keys()):\n",
    "                unique_topic_scroll_freq[k] = []\n",
    "\n",
    "    # Find the average read time across each topic\n",
    "    ## Group by user ID\n",
    "    ### Look at article_id for whichever topics the article is included in add that readtime and scroll percentage\n",
    "        tmp_dict = {k:v for k,v in zip(topics, read)}\n",
    "\n",
    "        for k,v in zip(tmp_dict.keys(), tmp_dict.values()):\n",
    "\n",
    "            if (k in unique_topic_read_freq.keys()):\n",
    "                tmp_array= np.append(unique_topic_read_freq[k],v)\n",
    "                unique_topic_read_freq[k] = tmp_array\n",
    "            if (k not in unique_topic_read_freq.keys()):\n",
    "                unique_topic_read_freq[k] = []\n",
    "\n",
    "    \n",
    "    ## Unique User Topics\n",
    "    # Get rid of duplicate values\n",
    "    unique_topics = list(set(topics))\n",
    "\n",
    "    \n",
    "    # Populate our dict\n",
    "    for i in unique_topics:\n",
    "        \n",
    "        if i not in unique_users_topics_freq:\n",
    "            unique_users_topics_freq[i] = 1\n",
    "        else:\n",
    "            unique_users_topics_freq[i] +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f54e8",
   "metadata": {},
   "source": [
    "### Distribution of Topics across users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa6df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the distribution of topics look like lets sort it?\n",
    "sorted_topic_freq = dict(sorted(unique_users_topics_freq.items(), key = lambda x: x[1], reverse = True))\n",
    "\n",
    "\n",
    "indices = [x for x in sorted_topic_freq.keys()]\n",
    "values = [x for x in sorted_topic_freq.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Bar(x = indices, y = values,\n",
    "                         \n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab41490",
   "metadata": {},
   "source": [
    "### Average readtime per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bea6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average read times across each topic\n",
    "\n",
    "# Get the average scroll length for each article\n",
    "for k,v in zip(unique_topic_read_freq.keys(), unique_topic_read_freq.values()):\n",
    "    unique_topic_read_freq[k] = np.nanmean(v)\n",
    "\n",
    "sorted_unique_topic_read_freq = dict(sorted(unique_topic_read_freq.items(), key = lambda x: x[1], reverse = True))\n",
    "\n",
    "\n",
    "indices = [x for x in sorted_unique_topic_read_freq . keys()]\n",
    "values = [x for x in sorted_unique_topic_read_freq.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Bar(x = indices, y = values,\n",
    "                         \n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973adab",
   "metadata": {},
   "source": [
    "### Average scroll perct per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6732699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average scroll percentages across each topic\n",
    "\n",
    "# Get the average scroll length for each article\n",
    "for k,v in zip(unique_topic_scroll_freq.keys(), unique_topic_scroll_freq.values()):\n",
    "    unique_topic_scroll_freq[k] = np.nanmean(v)\n",
    "\n",
    "sorted_unique_topic_scroll_freq = dict(sorted(unique_topic_scroll_freq.items(), key = lambda x: x[1], reverse = True))\n",
    "\n",
    "\n",
    "indices = [x for x in sorted_unique_topic_scroll_freq . keys()]\n",
    "values = [x for x in sorted_unique_topic_scroll_freq.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Bar(x = indices, y = values,\n",
    "                         \n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97be17",
   "metadata": {},
   "source": [
    "### Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144c7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of each unqiue topic in a specific session \n",
    "topics = df.groupby(by = 'session_id')['topics'].apply(list)\n",
    "\n",
    "# Get the list of each unique timestamp for these sessions\n",
    "timestamps = df.groupby(by = 'session_id')['impression_time'].apply(list)\n",
    "\n",
    "# Get all the unique topics\n",
    "\n",
    "# Get all the unique topics\n",
    "unique_topics = []\n",
    "for i in range(36795):\n",
    "    for j in range(0, len(topics.values[i][0])):\n",
    "        tmp = topics.values[i][0][j]\n",
    "        if tmp not in unique_topics:\n",
    "            unique_topics.append(tmp)\n",
    "\n",
    "\n",
    "unique_topics = sorted(unique_topics)\n",
    "\n",
    "# Get all unique dates\n",
    "timestamps = df.groupby(by = 'session_id')['impression_time'].apply(list)\n",
    "\n",
    "unique_dates = []\n",
    "unique_hours= [str(i) if i > 9 else str(0) + str(i) for i in range(24)]\n",
    "\n",
    "for i in range(len(timestamps.values)):\n",
    "    for j in range(len(timestamps.values[i])):\n",
    "        tmp_datetime = timestamps.values[i][j]\n",
    "        tmp_date = tmp_datetime.strftime('%m/%d/%Y')\n",
    "        if tmp_date not in unique_dates:\n",
    "            unique_dates.append(tmp_date)\n",
    "\n",
    "\n",
    "unique_dates = sorted(unique_dates)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_topic_daily_activity  = {k:{k:0 for k in unique_dates} for k in unique_topics}\n",
    "unique_topic_hourly_activity  = {k:{k:0 for k in unique_hours} for k in unique_topics}\n",
    "\n",
    "# Populate the dictionary\n",
    "for i in zip(range(len(topics.values))):\n",
    "    for j, k  in zip(range(0, len(topics.values[i][0])), range(0, len(i))):\n",
    "        tmp = topics.values[i][0][j]\n",
    "        tmp_datetime = timestamps.values[i][k]\n",
    "        tmp_date = tmp_datetime.strftime('%m/%d/%Y')\n",
    "        tmp_time = tmp_datetime.strftime('%H')\n",
    "\n",
    "        # Add to dictionary\n",
    "        unique_topic_daily_activity[tmp][tmp_date] +=1\n",
    "        unique_topic_hourly_activity[tmp][tmp_time] +=1\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e4838",
   "metadata": {},
   "source": [
    "Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ddb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for topic in unique_topic_daily_activity.keys():\n",
    "    # What does the daily user activity look like?\n",
    "    indices = [x for x in unique_topic_daily_activity[topic].keys()]\n",
    "    values = [x for x in unique_topic_daily_activity[topic].values()]\n",
    "\n",
    "\n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(x = indices, y = values,\n",
    "                            mode = 'lines+markers'\n",
    "                            )\n",
    "\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03917388",
   "metadata": {},
   "source": [
    "Hourly Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fe30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for topic in unique_topic_hourly_activity.keys():\n",
    "    # What does the daily user activity look like?\n",
    "    indices = [x for x in unique_topic_hourly_activity[topic].keys()]\n",
    "    values = [x for x in unique_topic_hourly_activity[topic].values()]\n",
    "\n",
    "\n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(x = indices, y = values,\n",
    "                            mode = 'lines+markers'\n",
    "                            )\n",
    "\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499b9a7",
   "metadata": {},
   "source": [
    "## Article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4919c54",
   "metadata": {},
   "source": [
    "### Average readtime per article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each article, what was each users read time\n",
    "\n",
    "\n",
    "## Get all unique ids in a list\n",
    "\n",
    "unique_user_ids = df['user_id'].values[0:1000]\n",
    "\n",
    "## We take the set because the scroll, article per user is joined in a list for every user id (so just take the set of it!)\n",
    "unique_user_ids = set(unique_user_ids)\n",
    "\n",
    "\n",
    "unique_article_ids = df['article_id'].unique()\n",
    "unique_article_ids= unique_article_ids[~np.isnan(unique_article_ids)]\n",
    "\n",
    "\n",
    "# Create dictionaries\n",
    "\n",
    "unique_article_read = {k: [0] for k in unique_article_ids}\n",
    "\n",
    "for id in unique_user_ids:\n",
    "    # Get the subset of that user id\n",
    "    tmp_df = df[df['user_id'] == id]\n",
    "\n",
    "    # Now lets go through each scroll and article\n",
    "    ## Iterate through each of the df\n",
    "    indices = np.array(tmp_df.index)\n",
    "    for i in indices:\n",
    "        tmp_dict = {}\n",
    "        # Select the scroll / article of that indice and \n",
    "        tmp_read = tmp_df['read_time_fixed'][i]\n",
    "\n",
    "        tmp_article = tmp_df['article_id_fixed'][i]\n",
    "\n",
    "        read = [x for x in tmp_read]\n",
    "        \n",
    "        articles = [np.int64(x) for x in tmp_article]\n",
    "    \n",
    "        tmp_dict = {k:v for k,v in zip(articles, read)}\n",
    "\n",
    "\n",
    "        for k,v in zip(tmp_dict.keys(), tmp_dict.values()):\n",
    "\n",
    "            #if unique_article_scroll.get(k) != None:\n",
    "            #    unique_article_scroll[k] += v\n",
    "            if (k in unique_article_read.keys()) & (np.isnan(v) == False):\n",
    "                tmp_array= np.append(unique_article_read[k],v)\n",
    "                unique_article_read[k] = tmp_array\n",
    "        \n",
    "    \n",
    "    # Get the average scroll length for each article\n",
    "    for k,v in zip(unique_article_read.keys(), unique_article_read.values()):\n",
    "        unique_article_read[k] = np.mean(v)\n",
    "\n",
    "\n",
    "\n",
    "# What does the hourly user activity look like?\n",
    "indices = [x for x in unique_article_read.keys()]\n",
    "values = [x for x in unique_article_read.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(x = indices, y = values,\n",
    "                         mode = 'markers'\n",
    "                         )\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b8c77",
   "metadata": {},
   "source": [
    "### Average scroll pct per article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeca6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each article, what was each users scroll percentage + read time? \n",
    "\n",
    "\n",
    "## Get all unique ids in a list\n",
    "\n",
    "unique_user_ids = df['user_id'].values[0:2000]\n",
    "\n",
    "## We take the set because the scroll, article per user is joined in a list for every user id (so just take the set of it!)\n",
    "unique_user_ids = set(unique_user_ids)\n",
    "\n",
    "\n",
    "unique_article_ids = df['article_id'].unique()\n",
    "unique_article_ids= unique_article_ids[~np.isnan(unique_article_ids)]\n",
    "\n",
    "# Create dictionaries\n",
    "\n",
    "unique_article_scroll = {k: [0] for k in unique_article_ids}\n",
    "\n",
    "for id in unique_user_ids:\n",
    "    # Get the subset of that user id\n",
    "    tmp_df = df[df['user_id'] == id]\n",
    "\n",
    "    # Now lets go through each scroll and article\n",
    "    ## Iterate through each of the df\n",
    "    indices = np.array(tmp_df.index)\n",
    "    for i in indices:\n",
    "        tmp_dict = {}\n",
    "        # Select the scroll / article of that indice and \n",
    "        tmp_scroll = tmp_df['scroll_percentage_fixed'][i]\n",
    "\n",
    "        tmp_article = tmp_df['article_id_fixed'][i]\n",
    "\n",
    "        scroll = [x for x in tmp_scroll]\n",
    "        \n",
    "        articles = [np.int64(x) for x in tmp_article]\n",
    "    \n",
    "        tmp_dict = {k:v for k,v in zip(articles, scroll)}\n",
    "\n",
    "\n",
    "        for k,v in zip(tmp_dict.keys(), tmp_dict.values()):\n",
    "\n",
    "            if (k in unique_article_scroll.keys()) & (np.isnan(v) == False):\n",
    "                tmp_array= np.append(unique_article_scroll[k],v)\n",
    "                unique_article_scroll[k] = tmp_array\n",
    "        \n",
    "    \n",
    "# Get the average scroll length for each article\n",
    "for k,v in zip(unique_article_scroll.keys(), unique_article_scroll.values()):\n",
    "    unique_article_scroll[k] = np.mean(v)\n",
    "\n",
    "\n",
    "\n",
    "indices = [x for x in unique_article_scroll.keys()]\n",
    "avg_scroll_pct = [x for x in unique_article_scroll.values()]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Histogram(x=avg_scroll_pct)\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4503e",
   "metadata": {},
   "source": [
    "# Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall distribtuion of devices\n",
    "\n",
    "df['device_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dffc83",
   "metadata": {},
   "source": [
    "### Readtime per device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc390dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readtime per device\n",
    "\n",
    "## Get indices with different devices \n",
    "### Color based on label\n",
    "#### Histogram -> Bar graph for avg?\n",
    "\n",
    "device_1 = df[df['device_type'] == 1]['read_time']\n",
    "device_2 = df[df['device_type'] == 2]['read_time']\n",
    "device_3 = df[df['device_type'] == 3]['read_time']\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=device_1))\n",
    "fig.add_trace(go.Histogram(x=device_2))\n",
    "fig.add_trace(go.Histogram(x=device_3))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.55)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f164a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average readtime per device\n",
    "\n",
    "## Get indices with different devices \n",
    "### Color based on label\n",
    "#### Histogram -> Bar graph for avg?\n",
    "\n",
    "device_1 = df[df['device_type'] == 1]['read_time']\n",
    "device_2 = df[df['device_type'] == 2]['read_time']\n",
    "device_3 = df[df['device_type'] == 3]['read_time']\n",
    "\n",
    "avg_readtime_device = [device_1.mean(), device_2.mean(), device_3.mean()]\n",
    "devices = ['Device 1', 'Device 2', 'Device 3']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=devices, y = avg_readtime_device, textfont_size=20))\n",
    "\n",
    "# Overlay both histograms\n",
    "#fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e86ec",
   "metadata": {},
   "source": [
    "### Scroll time per device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll pct per device (scatter plot probably better)\n",
    "\n",
    "## Get indices with different devices \n",
    "### Color based on label\n",
    "#### Histogram -> Bar graph for avg?\n",
    "\n",
    "device_1 = df[(df['device_type'] == 1)]['scroll_percentage']\n",
    "device_2 = df[df['device_type'] == 2]['scroll_percentage']\n",
    "device_3 = df[df['device_type'] == 3]['scroll_percentage']\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=device_1))\n",
    "fig.add_trace(go.Histogram(x=device_2))\n",
    "fig.add_trace(go.Histogram(x=device_3))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.55)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba243c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average readtime per device\n",
    "\n",
    "## Get indices with different devices \n",
    "### Color based on label\n",
    "#### Histogram -> Bar graph for avg?\n",
    "\n",
    "device_1 = df[df['device_type'] == 1]['scroll_percentage']\n",
    "device_2 = df[df['device_type'] == 2]['scroll_percentage']\n",
    "device_3 = df[df['device_type'] == 3]['scroll_percentage']\n",
    "\n",
    "avg_scrollpct_device = [device_1.mean(), device_2.mean(), device_3.mean()]\n",
    "devices = ['Device 1', 'Device 2', 'Device 3']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=devices, y = avg_scrollpct_device, textfont_size=20))\n",
    "\n",
    "# Overlay both histograms\n",
    "#fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b7ff5",
   "metadata": {},
   "source": [
    "# If subscriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_subscriber'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76723f43",
   "metadata": {},
   "source": [
    "### Read time for subscriber vs non-subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution paid subscribers\n",
    "\n",
    "#### Histogram -> Bar graph for avg?\n",
    "\n",
    "subscriber= df[df['is_subscriber'] == True]['read_time']\n",
    "not_subscriber = df[df['is_subscriber'] == False]['read_time']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=subscriber))\n",
    "fig.add_trace(go.Histogram(x=not_subscriber))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average readtime per device\n",
    "\n",
    "## Get indices with different devices \n",
    "### Color based on label\n",
    "#### Histogram -> Bar graph for avg?\n",
    "\n",
    "subscriber= df[df['is_subscriber'] == True]['read_time']\n",
    "not_subscriber = df[df['is_subscriber'] == False]['read_time']\n",
    "\n",
    "avg_readtime_is_subscriber= [subscriber.mean(), not_subscriber.mean()]\n",
    "is_subscriber = ['Yes', 'No']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=is_subscriber, y = avg_readtime_is_subscriber, textfont_size=20))\n",
    "\n",
    "# Overlay both histograms\n",
    "#fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47680f96",
   "metadata": {},
   "source": [
    "### Scroll percentage if subscriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution paid subscribers\n",
    "\n",
    "#### Histogram -> Bar graph for avg?\n",
    "\n",
    "subscriber= df[df['is_subscriber'] == True]['scroll_percentage']\n",
    "not_subscriber = df[df['is_subscriber'] == False]['scroll_percentage']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=subscriber))\n",
    "fig.add_trace(go.Histogram(x=not_subscriber))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average readtime per device\n",
    "\n",
    "## Get indices with different devices \n",
    "### Color based on label\n",
    "#### Histogram -> Bar graph for avg?\n",
    "\n",
    "subscriber= df[df['is_subscriber'] == True]['scroll_percentage']\n",
    "not_subscriber = df[df['is_subscriber'] == False]['scroll_percentage']\n",
    "\n",
    "avg_scrollpct_is_subscriber= [subscriber.mean(), not_subscriber.mean()]\n",
    "is_subscriber = ['Yes', 'No']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=is_subscriber, y = avg_scrollpct_is_subscriber, textfont_size=20))\n",
    "\n",
    "# Overlay both histograms\n",
    "#fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469168b",
   "metadata": {},
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8dcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Genders\n",
    "df['gender'].value_counts()\n",
    "\n",
    "# Gender specific topic \n",
    "\n",
    "# Gender readtime / scroll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0c923",
   "metadata": {},
   "source": [
    "### Read time per gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readtime per gender\n",
    "\n",
    "male = df[df['gender'] == 0]['read_time']\n",
    "female = df[df['gender'] == 1]['read_time']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=male))\n",
    "fig.add_trace(go.Histogram(x=female))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average readtime per device\n",
    "\n",
    "## Get indices with different devices \n",
    "### Color based on label\n",
    "#### Histogram -> Bar graph for avg?\n",
    "\n",
    "male = df[df['gender'] == 0]['read_time']\n",
    "female = df[df['gender'] == 1]['read_time']\n",
    "\n",
    "avg_readtime_gender= [male.mean(), female.mean()]\n",
    "gender = ['Male', 'Female']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=gender, y = avg_readtime_gender, textfont_size=20))\n",
    "\n",
    "# Overlay both histograms\n",
    "#fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd149a",
   "metadata": {},
   "source": [
    "Scrolltime per gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2bf15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll pct per gender\n",
    "male = df[df['gender'] == 0]['scroll_percentage']\n",
    "female = df[df['gender'] == 1]['scroll_percentage']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=male))\n",
    "fig.add_trace(go.Histogram(x=female))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669aa3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = df[df['gender'] == 0]['scroll_percentage']\n",
    "female = df[df['gender'] == 1]['scroll_percentage']\n",
    "\n",
    "avg_scrollpct_gender= [male.mean(), female.mean()]\n",
    "gender = ['Male', 'Female']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=gender, y = avg_scrollpct_gender, textfont_size=20))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e32b90",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c5c75",
   "metadata": {},
   "source": [
    "### Age Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].value_counts()\n",
    "\n",
    "indices = df['age'].value_counts().sort_index().index\n",
    "values = df['age'].value_counts().sort_index().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d84e0",
   "metadata": {},
   "source": [
    "#### Average readtime per age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age readtime/scroll\n",
    "## Binned by 10-19, 20-29, etc\n",
    "\n",
    "indices = df['age'].value_counts().sort_index().index\n",
    "values = df['age'].value_counts().sort_index().values\n",
    "\n",
    "\n",
    "\n",
    "# Create graph object\n",
    "fig = go.Figure()\n",
    "\n",
    "# for each age group add a readtime \n",
    "for age in indices:\n",
    "    read_time = df[df['age'] == age]['read_time']\n",
    "    fig.add_trace(go.Histogram(x=read_time))\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average read time\n",
    "## Binned by 10-19, 20-29, etc\n",
    "\n",
    "indices = df['age'].value_counts().sort_index().index\n",
    "values = df['age'].value_counts().sort_index().values\n",
    "\n",
    "\n",
    "# Create graph object\n",
    "fig = go.Figure()\n",
    "\n",
    "# for each age group add a readtime \n",
    "for age in indices:\n",
    "    avg_read_time = df[df['age'] == age]['read_time'].mean()\n",
    "    fig.add_trace(go.Bar(x=[age], y = [avg_read_time], textfont_size=20))\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3883ce0",
   "metadata": {},
   "source": [
    "Average Scroll PCt per age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d988f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df['age'].value_counts().sort_index().index\n",
    "values = df['age'].value_counts().sort_index().values\n",
    "\n",
    "# Create graph object\n",
    "fig = go.Figure()\n",
    "\n",
    "# for each age group add a readtime \n",
    "for age in indices:\n",
    "    scroll_pct = df[df['age'] == age]['scroll_percentage']\n",
    "    fig.add_trace(go.Histogram(x=scroll_pct))\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df['age'].value_counts().sort_index().index\n",
    "values = df['age'].value_counts().sort_index().values\n",
    "\n",
    "# Create graph object\n",
    "fig = go.Figure()\n",
    "\n",
    "# for each age group add a readtime \n",
    "for age in indices:\n",
    "    avg_scroll_pct = df[df['age'] == age]['scroll_percentage'].mean()\n",
    "    fig.add_trace(go.Bar(x=[age], y = [avg_scroll_pct], textfont_size=20))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e40744",
   "metadata": {},
   "source": [
    "## Postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b31209f",
   "metadata": {},
   "source": [
    "### Distribution of Post Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['postcode'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5a212",
   "metadata": {},
   "source": [
    "### Average Read Time in each postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3bf9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df['postcode'].value_counts().sort_index().index\n",
    "values = df['postcode'].value_counts().sort_index().values\n",
    "\n",
    "# Create graph object\n",
    "fig = go.Figure()\n",
    "\n",
    "# for each post code add a readtime \n",
    "for postcode in indices:\n",
    "    read_time = df[df['postcode'] == postcode]['read_time']\n",
    "    fig.add_trace(go.Histogram(x=read_time))\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df['postcode'].value_counts().sort_index().index\n",
    "values = df['postcode'].value_counts().sort_index().values\n",
    "\n",
    "# Create graph object\n",
    "fig = go.Figure()\n",
    "\n",
    "# for each post code add a readtime \n",
    "for postcode in indices:\n",
    "    avg_read_time = df[df['postcode'] == postcode]['read_time'].mean()\n",
    "    fig.add_trace(go.Bar(x=[postcode], y = [avg_read_time], textfont_size=20))\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13bde99",
   "metadata": {},
   "source": [
    "### Average Scroll pct in each postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df['postcode'].value_counts().sort_index().index\n",
    "values = df['postcode'].value_counts().sort_index().values\n",
    "\n",
    "# Create graph object\n",
    "fig = go.Figure()\n",
    "\n",
    "# for each post code add a readtime \n",
    "for postcode in indices:\n",
    "    scroll_pct = df[df['postcode'] == postcode]['scroll_percentage']\n",
    "    fig.add_trace(go.Histogram(x=scroll_pct))\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d829609",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = df['postcode'].value_counts().sort_index().index\n",
    "values = df['postcode'].value_counts().sort_index().values\n",
    "\n",
    "# Create graph object\n",
    "fig = go.Figure()\n",
    "\n",
    "# for each post code add a readtime \n",
    "for postcode in indices:\n",
    "    avg_scroll_pct = df[df['postcode'] == postcode]['scroll_percentage'].mean()\n",
    "    fig.add_trace(go.Bar(x=[postcode], y = [avg_scroll_pct], textfont_size=20))\n",
    "\n",
    "\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique articles are clicked in a session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80594da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
