{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a295dea",
   "metadata": {},
   "source": [
    "# 2024 Recsys Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92703771",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3934a3",
   "metadata": {},
   "source": [
    "This year's challenge focuses on online news recommendation, addressing both the technical and normative challenges inherent in designing effective and responsible recommender systems for news publishing. The challenge will delve into the unique aspects of news recommendation, including modeling user preferences based on implicit behavior, accounting for the influence of the news agenda on user interests, and managing the rapid decay of news items. Furthermore, our challenge embraces the normative complexities, involving investigating the effects of recommender systems on the news flow and whether they resonate with editorial values. [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18760b2a",
   "metadata": {},
   "source": [
    "## Challenge Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237298c2-2986-4bba-bcbd-5ff27e361919",
   "metadata": {},
   "source": [
    "The Ekstra Bladet RecSys Challenge aims to predict which article a user will click on from a list of articles that were seen during a specific impression. Utilizing the user's click history, session details (like time and device used), and personal metadata (including gender and age), along with a list of candidate news articles listed in an impression log, the challenge's objective is to rank the candidate articles based on the user's personal preferences. This involves developing models that encapsulate both the users and the articles through their content and the users' interests. The models are to estimate the likelihood of a user clicking on each article by evaluating the compatibility between the article's content and the user's preferences. The articles are ranked based on these likelihood scores, and the precision of these rankings is measured against the actual selections made by users. [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788cf29",
   "metadata": {},
   "source": [
    "## Dataset Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1766e23f",
   "metadata": {},
   "source": [
    "The Ekstra Bladet News Recommendation Dataset (EB-NeRD) was created to support advancements in news recommendation research. It was collected from user behavior logs at Ekstra Bladet. We collected behavior logs from active users during the 6 weeks from April 27 to June 8, 2023. This timeframe was selected to avoid major events, e.g., holidays or elections, that could trigger atypical behavior at Ekstra Bladet. The active users were defined as users who had at least 5 and at most 1,000 news click records in a three-week period from May 18 to June 8, 2023. To protect user privacy, every user was delinked from the production system when securely hashed into an anonymized ID using one-time salt mapping. Alongside, we provide Danish news articles published by Ekstra Bladet. Each article is enriched with textual context features such as title, abstract, body, categories, among others. Furthermore, we provide features that have been generated by proprietary models, including topics, named entity recognition (NER), and article embeddings [2]\n",
    "\n",
    "For more information on the [dataset](https://recsys.eb.dk/dataset/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb08b9d",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] [RecySys Challenge 2024 Logistics](https://recsys.eb.dk/)\n",
    "\n",
    "[2] [Ekstra Bladet News Recommendation Dataset](https://recsys.eb.dk/dataset/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e0d1c",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97e6cd",
   "metadata": {},
   "source": [
    "### Notebook Organization\n",
    "### This purpose of this notebook is for EDA only. \n",
    "\n",
    "- Logistics\n",
    "- EDA \n",
    "    - Data Preprocessing\n",
    "    - Functions\n",
    "        - Plot Functions\n",
    "        - Feature Functions\n",
    "            - Article\n",
    "            - User\n",
    "            - Topic\n",
    "            - Activity\n",
    "    - Feature Analysis\n",
    "        - Overall Feature Analysis\n",
    "        - Article\n",
    "        - User\n",
    "        - Session\n",
    "        - Topic\n",
    "        - Devices\n",
    "        - If subscriber\n",
    "        - Gender\n",
    "        - Age\n",
    "        - Postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e806296",
   "metadata": {},
   "source": [
    "We need to establish specific metrics and analyze how different features impact those metrics. Our platform generates revenue through both subscriptions and advertisements. User engagement is crucial because the more time users spend reading new articles, the greater our advertisement revenue. With this in focus, let's start with exploratory data analysis (EDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927be23c",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f05b58-dde3-4d5f-87a2-f20ad71cd62b",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b4caea",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d0f39",
   "metadata": {},
   "source": [
    "Let's import our packages used for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651173e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from datetime import datetime\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616fa6a4-e47a-4116-82f5-896d6893a00e",
   "metadata": {},
   "source": [
    "Load in the three separate data sources of the dataset:\n",
    "\n",
    "**Articles**: Detailed information of news articles.[*](https://recsys.eb.dk/dataset/#articles)\n",
    "\n",
    "**Behaviors**: Impression Logs. [*](https://recsys.eb.dk/dataset/#behaviors)\n",
    "\n",
    "**History**: Click histories of users. [*](https://recsys.eb.dk/dataset/#history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a57c46-4e08-4299-8a69-12d45e274b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in various dataframes\n",
    "# Articles\n",
    "df_art = pd.read_parquet(\"Data/Small/articles.parquet\")\n",
    "\n",
    "# Behaviors\n",
    "df_bev = pd.read_parquet(\"Data/Small/train/behaviors.parquet\")\n",
    "\n",
    "# History\n",
    "df_his = pd.read_parquet(\"Data/Small/train/history.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d447c",
   "metadata": {},
   "source": [
    "What feature can we join the data sources on?\n",
    "\n",
    "- Articles & Behavior: Article ID\n",
    "\n",
    "- History & Behavior: User ID\n",
    "\n",
    "Before we can join, we need to modify the behavior['article_ids_clicked'] column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eaa9148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datatype of column first\n",
    "df_bev['article_id'] = df_bev['article_id'].apply(lambda x: x if isinstance(x, str) else int(x) if not np.isnan(x) else x)\n",
    "\n",
    "# Join bevhaiors to article\n",
    "df = df_bev.join(df_art.set_index(\"article_id\"), on=\"article_id\")\n",
    "\n",
    "# Join bevhaiors to history\n",
    "df = df.join(df_his.set_index(\"user_id\"), on=\"user_id\")\n",
    "\n",
    "# Drop all other dataframes from me\n",
    "df_bev = []\n",
    "df_his = []\n",
    "df_art = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e87a8d8",
   "metadata": {},
   "source": [
    "More preprocessing needed before we can begin further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_(x):\n",
    "    \"\"\" \n",
    "    Changes the device input from a int to a str\n",
    "    Keyword arguments:\n",
    "        x -- int\n",
    "    Output:\n",
    "        str\n",
    "    \"\"\"\n",
    "    if x == 1:\n",
    "        return 'Desktop'\n",
    "    elif x == 2:\n",
    "        return 'Mobile'\n",
    "    else:\n",
    "        return 'Tablet'\n",
    "\n",
    "def gender_(x):\n",
    "    \"\"\" \n",
    "    Changes the gender input from a float to a str\n",
    "    Keyword arguments:\n",
    "        x -- float\n",
    "    Output:\n",
    "        str\n",
    "    \"\"\"\n",
    "    if x == 0.0:\n",
    "        return 'Male'\n",
    "    elif x == 1.0:\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def postcodes_(x):\n",
    "    \"\"\" \n",
    "    Changes the postcodes input from a float to a str\n",
    "    Keyword arguments:\n",
    "        x -- float\n",
    "    Output:\n",
    "        str\n",
    "    \"\"\"\n",
    "    if x == 0.0:\n",
    "        return 'Metropolitan'\n",
    "    elif x == 1.0:\n",
    "        return 'Rural District'\n",
    "\n",
    "    elif x == 2.0:\n",
    "        return 'Municipality'\n",
    "\n",
    "    elif x == 3.0:\n",
    "        return 'Provincial'\n",
    "\n",
    "    elif x == 4.0:\n",
    "        return 'Big City'\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df.dropna(subset=['article_id'], inplace=True)\n",
    "\n",
    "# Change article IDs into int\n",
    "df['article_id'] = df['article_id'].apply(lambda x: int(x))\n",
    "df['article_id'] = df['article_id'].astype(np.int64)\n",
    "\n",
    "# Change age from int to string\n",
    "df['device_type'] = df['device_type'].apply(lambda x: device_(x))\n",
    "\n",
    "# Change genders from float to string\n",
    "df['gender'] = df['gender'].apply(lambda x: gender_(x))\n",
    "\n",
    "# Change age to str it's a range\n",
    "df['age'] = df['age'].astype('Int64')\n",
    "df['age'] = df['age'].astype(str)\n",
    "df['age'] = df['age'].apply(\n",
    "    lambda x: x if x == '<NA>' else x + ' - ' + x[0] + '9')\n",
    "\n",
    "\n",
    "# Change postcodes from int to str\n",
    "df['postcode'] = df['postcode'].apply(lambda x: postcodes_(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3427472",
   "metadata": {},
   "source": [
    "Next section will be on all the helper functions used in this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2493e",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a050d",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b3df4",
   "metadata": {},
   "source": [
    "### Plot Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0963e",
   "metadata": {},
   "source": [
    "These are all functions related to visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd47af3",
   "metadata": {},
   "source": [
    "#### Single & Multiple Subset Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db41661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_subset_bar(df_, feature_, xaxis_title, yrange):\n",
    "    \"\"\" \n",
    "    Displays bar plot for a feature that has a single category\n",
    "    Keyword arguments:\n",
    "        df_ -- list\n",
    "        feature_ -- str\n",
    "        xaxis_title -- str\n",
    "        yrange -- list of ints: [0, 5]\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "    # Index and Values\n",
    "    indices = ['<b>{}<b>'.format(xaxis_title)]\n",
    "    values_ = [len(df_[feature_].unique())]\n",
    "\n",
    "    # Instantiate figure object\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Append Bar trace\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x= indices, y=values_,\n",
    "            width=[0.3], text='<b>{}<b>'.format(values_[0]),\n",
    "        )\n",
    "\n",
    "    )\n",
    "    \n",
    "    # Update axis properties\n",
    "    fig.update_yaxes(\n",
    "        title_text='<b>Count<b>', range=yrange\n",
    "    )\n",
    "\n",
    "    # Update trace properties\n",
    "    fig.update_traces(\n",
    "        textposition='outside',\n",
    "        textfont=dict(\n",
    "            family='sans serif',\n",
    "            size=16,\n",
    "            color='#1f77b4'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout of plot\n",
    "    fig.update_layout(\n",
    "        title='<b>Total {}<b>'.format(xaxis_title),\n",
    "        height=500, width=1000,\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=16,\n",
    "        ),\n",
    "        margin=dict(\n",
    "            l=100, r=50,\n",
    "            t=100, b=50,\n",
    "            pad=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_subset_bar(df_, feature_, yrange, xaxis_title):\n",
    "    \"\"\" \n",
    "    Displays bar plot for a feature that has multiple categories.\n",
    "    Keyword arguments:\n",
    "        df_ -- list\n",
    "        feature_ -- str\n",
    "        yrange -- list of ints: [0, 5]\n",
    "        xaxis_title -- str\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "\n",
    "    # Assign tmp_df based on feature\n",
    "    if feature_ == 'age':\n",
    "        tmp_df = df_[df_['age'] != '<NA>']\n",
    "    else:\n",
    "        tmp_df = df_[~df_[feature_].isnull()]\n",
    "\n",
    "    # Create a category list\n",
    "    categories = [d for d in tmp_df[feature_].unique()]\n",
    "    categories.sort()\n",
    "\n",
    "    # Instantiate a Figure object\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Iterate through each category and produce a barplot for that category\n",
    "    for category_ in categories:\n",
    "        # Record the count\n",
    "        count= len(tmp_df[tmp_df[feature_] == category_])\n",
    "        # Add Bar trace\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x= [str(category_)], y = [count],\n",
    "                text = '<b>{}<b>'.format(count), \n",
    "                name= str(category_)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    # Update axis properties\n",
    "    fig.update_yaxes(\n",
    "        title_text= '<b>Count<b>', range = yrange, type = 'log'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        title_text= '<b>{}<b>'.format(str(xaxis_title))\n",
    "    )\n",
    "\n",
    "    # Update trace properties\n",
    "    fig.update_traces(\n",
    "        textposition='outside',\n",
    "        textfont=dict(\n",
    "            family='sans serif',\n",
    "            size=16,\n",
    "            color='#1f77b4'\n",
    "        )\n",
    "    )\n",
    "            \n",
    "    # Update layout of plot\n",
    "    fig.update_layout(\n",
    "        title = '<b>Distribution of {}<b>'.format(xaxis_title) ,\n",
    "        uniformtext_minsize=8, uniformtext_mode='hide',  \n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=16,\n",
    "        ),\n",
    "        margin=dict(\n",
    "            l=100, r=50,\n",
    "            t=100, b=50,\n",
    "            pad=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61281d8c",
   "metadata": {},
   "source": [
    "#### Single & Multiple Subset Histogram, Box Plot and Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_subset_feature_visualization(\n",
    "    df_,\n",
    "    feature_,\n",
    "    feature_title,\n",
    "    data_title, histogram_xaxis_title ) -> 'Graph':\n",
    "    \"\"\" \n",
    "    Displays multiple plots: Histogram, Box, and Bar plots based on a feature given.\n",
    "    Keyword arguments:\n",
    "        df_ -- list\n",
    "        feature_ -- str\n",
    "        feature_title -- str\n",
    "        histogram_xaxis_title -- str\n",
    "        data_title -- str\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "    # Create subplots object\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1, subplot_titles=(\"<b>Histogram<b>\", \"<b>Box plot<b>\", \"<b>Average {}<b>\".format(feature_title)),\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "\n",
    "    # Instantiate a tmp df which has no null values\n",
    "    tmp_df = df_[~df_[feature_].isnull()]\n",
    "    values = tmp_df[feature_].values\n",
    "\n",
    "    # Average\n",
    "    average = round(float(values.mean()), 2)\n",
    "\n",
    "    # Histogram \n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=values, name='Histogram'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Box Plot\n",
    "    xo = ['<b>{}<b>'.format(data_title) for x in range(0, len(values))]\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=values, x=xo, name='Box plot'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # Bar Plot\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=['<b>{}<b>'.format(data_title)], y=[average], width=[\n",
    "                  0.3], name='Bar plot'\n",
    "        ),  \n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "    # Update xaxis properties\n",
    "    fig.update_xaxes(\n",
    "        title_text='<b>{}<b>'.format(str(histogram_xaxis_title)), row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Update yaxis properties\n",
    "    fig.update_yaxes(\n",
    "        title_text='<b>Count<b>', row=1, col=1, type = 'log'\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text='<b>{}<b>'.format(str(feature_title)), row=2, col=1, type ='log'\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text='<b>{}<b>'.format(str(feature_title)), range=[0, 110], row=3, col=1\n",
    "    )\n",
    "\n",
    "    # Update suplot title sizes\n",
    "    fig.update_annotations(\n",
    "        font_size=20,\n",
    "    )\n",
    "\n",
    "    # Update title and height\n",
    "    fig.update_layout(\n",
    "        title_text=\"<b>Distributions of {} for {}<b>\".format(feature_title, data_title), height=750, width=1000,\n",
    "        uniformtext_minsize=8, uniformtext_mode='hide',\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=14,\n",
    "        ),\n",
    "        margin=dict(\n",
    "            l=100, r=50,\n",
    "            t=100, b=50,\n",
    "            pad=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b544d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_subset_feature_visualization(\n",
    "    df_,\n",
    "    feature_1, feature_2,\n",
    "    feature_2_title, feature_1_title,\n",
    "    histogram_xaxis_title\n",
    "    ) -> \"Graph\":\n",
    "    \"\"\" \n",
    "    Displays multiple plots: Histogram, Box, and Bar plots based on multiple features given.\n",
    "    Keyword arguments:\n",
    "        df_ -- list\n",
    "        feature_1 -- str\n",
    "        feature_2 -- str\n",
    "        feature_1_title -- str\n",
    "        feature_2_title -- str\n",
    "        histogram_xaxis_title -- str\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "\n",
    "    # Make subplots object\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1, subplot_titles=(\"<b>Histogram<b>\", \"<b>Box plot<b>\", \"<b>Average {} for {}<b>\".format(feature_2_title, feature_1_title))\n",
    "    )\n",
    "\n",
    "    # Assign tmp_df based on feature\n",
    "    if feature_1 == 'age':\n",
    "        tmp_df = df_[df_['age'] != '<NA>']\n",
    "    else:\n",
    "        tmp_df = df_[~df_[feature_1].isnull()]\n",
    "\n",
    "    # Create a category list from the feature given \n",
    "    categories = [d for d in tmp_df[feature_1].unique()]\n",
    "    categories.sort()\n",
    "\n",
    "    # Add a color for each category\n",
    "    colors_ = [\n",
    "    'slateblue', 'seagreen', 'tomato', 'sienna', 'silver',\n",
    "    'skyblue', 'sandybrown', 'slategray', 'snow', 'springreen'\n",
    "             ][0:len(categories)]\n",
    "\n",
    "\n",
    "    # Iterate through each category and produce a histogram, boxplot, and bar plots for that subset of the data\n",
    "    for category_,color_ in zip(categories, colors_):\n",
    "        subset_feature_2 = tmp_df[tmp_df[feature_1]== category_][feature_2].values\n",
    "        avg = round(float(tmp_df[tmp_df[feature_1] == category_][feature_2].mean()), 3)\n",
    "        # Add histogram\n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=subset_feature_2,\n",
    "                name=str(category_) + ' Histogram',\n",
    "                opacity = 0.75,\n",
    "                marker=dict(\n",
    "                    color=color_,\n",
    "                    )\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        # Add Boxplot\n",
    "        # Need to create an array that is similar to the array used in subset_feature_2, to name the traces!\n",
    "        xo = [str(category_) for x in range(0, len(subset_feature_2))]\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=subset_feature_2, x=xo,\n",
    "                name=str(category_) + ' Box',\n",
    "                marker=dict(\n",
    "                    color=color_,\n",
    "                    )\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "        # Add Bar\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=[str(category_)], y=[avg],\n",
    "                text='<b>{}<b>'.format(avg),\n",
    "                textposition='outside',\n",
    "                name=str(category_) + ' Bar',\n",
    "                marker=dict(\n",
    "                    color=color_,\n",
    "                    ),\n",
    "                textfont=dict(\n",
    "                    family='sans serif',\n",
    "                    size=18,\n",
    "                    color='#1f77b4'\n",
    "                    ),\n",
    "                \n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "\n",
    "    # Update xaxis properties\n",
    "    fig.update_xaxes(\n",
    "        title_text='<b>{}<b>'.format(str(histogram_xaxis_title)), row=1, col=1\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        title_text='<b>{}<b>'.format(str(feature_1_title)), row=2, col=1\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        title_text='<b>{}<b>'.format(str(feature_1_title)), row=3, col=1\n",
    "    )\n",
    "\n",
    "    # Update yaxis properties\n",
    "    fig.update_yaxes(\n",
    "        title_text='<b>Count<b>', row=1, col=1, type = 'log'\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text='<b>{}<b>'.format(str(feature_2_title)), row=2, col=1, type ='log'\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        title_text='<b>{}<b>'.format(str(feature_2_title)),\n",
    "        range=[0, 135], row=3, col=1\n",
    "    )\n",
    "\n",
    "    # Update subplot title sizes\n",
    "    fig.update_annotations(\n",
    "        font_size=20,\n",
    "    )\n",
    "\n",
    "    # Update title and height\n",
    "    fig.update_layout(\n",
    "        title_text=\"<b>Distributions of {} for {}<b>\".format(\n",
    "            feature_2_title, feature_1_title),\n",
    "        coloraxis = dict(\n",
    "            colorscale = 'Rdbu'\n",
    "        ),\n",
    "        barmode='overlay',\n",
    "        height=750, width=1000,\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=16,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca0696",
   "metadata": {},
   "source": [
    "#### Bar, Box, Scatter, and Activity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(\n",
    "    indices_, values_,\n",
    "    yrange_, xaxis_title,\n",
    "    yaxis_title, title_) -> \"Graph\":\n",
    "    \"\"\" \n",
    "    Bar Plot\n",
    "    Keyword arguments:\n",
    "        indices_ -- list\n",
    "        values_ -- list\n",
    "        yrange -- list of ints: [0, 5]\n",
    "        xaxis_title -- str\n",
    "        yaxis_title -- str\n",
    "        title_ -- str\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate figure object\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Iterate through each index and key pair and append a bar plot to the figure\n",
    "    for idx, val in zip(indices_, values_):\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x= [str(idx)], y = [val],\n",
    "                text = '<b>{}<b>'.format(val), \n",
    "                name= str(idx)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        \n",
    "    # Update axis properties\n",
    "    fig.update_yaxes(\n",
    "        title_text= '<b>{}<b>'.format(yaxis_title), range = yrange_, type = 'log'\n",
    "        )\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        title_text= '<b>{}<b>'.format(xaxis_title),\n",
    "        )\n",
    "\n",
    "    # Update trace properties\n",
    "    fig.update_traces(\n",
    "        textposition='outside',\n",
    "        textfont=dict(\n",
    "            family='sans serif',\n",
    "            size=16,\n",
    "            color='#1f77b4'\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    # Update layout of plot\n",
    "    fig.update_layout(\n",
    "        title = title_, height= 500, width = 1000,\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=16,\n",
    "            ),\n",
    "        margin=dict(\n",
    "            l=100, r=50,\n",
    "            t=100, b=50,\n",
    "            pad=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c89fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(\n",
    "    indices_, values_,\n",
    "    yrange_, xaxis_title,\n",
    "    yaxis_title, title_)-> 'Graph':\n",
    "    \"\"\" \n",
    "    Box Plot\n",
    "    Keyword arguments:\n",
    "        indices_ -- list\n",
    "        values_ -- list\n",
    "        yrange -- list of ints: [0, 5]\n",
    "        xaxis_title -- str\n",
    "        yaxis_title -- str\n",
    "        title_ -- str\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "\n",
    "    # Figure Object\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Iterate through each value and index pair and append a Boxplot trace to the Figure\n",
    "    for trace_, name_ in zip(values_, indices_):\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y = trace_, name = name_\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Update axis properties\n",
    "    fig.update_yaxes(\n",
    "        title_text= '<b>{}<b>'.format(yaxis_title), range = yrange_, type = 'log'\n",
    "        )\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        title_text= '<b>{}<b>'.format(xaxis_title),\n",
    "        )\n",
    "\n",
    "            \n",
    "    # Update layout of plot\n",
    "    fig.update_layout(\n",
    "        title = title_, height= 500, width = 1000,\n",
    "        uniformtext_minsize=8, uniformtext_mode='hide',  \n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=16,\n",
    "            ),\n",
    "        margin=dict(\n",
    "            l=100, r=50,\n",
    "            t=100, b=50,\n",
    "            pad=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(\n",
    "    indices_, values_,\n",
    "    yrange_, xaxis_title,\n",
    "    yaxis_title, title_) -> 'Graph':\n",
    "    \"\"\" \n",
    "    Scatter Plot\n",
    "    Keyword arguments:\n",
    "        indices_ -- list\n",
    "        values_ -- list\n",
    "        yrange -- list of ints: [0, 5]\n",
    "        xaxis_title -- str\n",
    "        yaxis_title -- str\n",
    "        title_ -- str\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "\n",
    "    # Figure Object\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add line plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=indices, y=values_,\n",
    "            mode='lines', name='Line',\n",
    "            marker=dict(\n",
    "                color=\"rgba(135, 206, 250, 0.5)\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Iterate through each index and value pair, and append a scatter plot trace\n",
    "    for idx, val in zip(indices_, values_):\n",
    "        # Add scatter trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[str(idx)], y=[val],\n",
    "                text='<b>{}<b>'.format(val),\n",
    "                name=str(idx),\n",
    "                marker=dict(\n",
    "                    size=12,\n",
    "            ),\n",
    "                mode='lines+markers+text'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update axis properties\n",
    "    fig.update_yaxes(\n",
    "        title_text='<b>{}<b>'.format(yaxis_title), range=yrange_\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title_text='<b>{}<b>'.format(xaxis_title),\n",
    "    )\n",
    "\n",
    "    # Update trace properties\n",
    "    fig.update_traces(\n",
    "        textposition='bottom center',\n",
    "        textfont=dict(\n",
    "            family='sans serif',\n",
    "            size=10,\n",
    "            color='#1f77b4'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout of plot\n",
    "    fig.update_layout(\n",
    "        title=title_, height=500, width=1000,\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=16,\n",
    "        ),\n",
    "        margin=dict(\n",
    "            l=100, r=50,\n",
    "            t=100, b=50,\n",
    "            pad=0\n",
    "        )\n",
    "\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d294517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_scatter(\n",
    "    dict_,  yrange_,\n",
    "    xaxis_title, yaxis_title,\n",
    "     title_) -> 'Graph':\n",
    "    \"\"\" \n",
    "    Scatter Plot of Daily or Hourly Activity \n",
    "    Keyword arguments:\n",
    "        dict_ -- dict object\n",
    "        yrange -- list of ints: [0, 5]\n",
    "        xaxis_title -- str\n",
    "        yaxis_title -- str\n",
    "        title_ -- str\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    # Iterate through each topic in dict and add that respective trace to the scatter plot!\n",
    "    for topic in dict_.keys():\n",
    "        indices = [x for x in dict_[topic].keys()]\n",
    "        values = [x for x in dict_[topic].values()]\n",
    "        # Add traces\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=indices, y=values, name=topic,\n",
    "                marker=dict(\n",
    "                    size=12,\n",
    "                ),\n",
    "                mode='lines+markers+text'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Update axis properties\n",
    "    fig.update_yaxes(\n",
    "        title_text='<b>{}<b>'.format(yaxis_title), range=yrange_\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title_text='<b>{}<b>'.format(xaxis_title),\n",
    "    )\n",
    "\n",
    "    # Update trace properties\n",
    "    fig.update_traces(\n",
    "        textposition='bottom center',\n",
    "        textfont=dict(\n",
    "            family='sans serif',\n",
    "            size=12,\n",
    "            color='#1f77b4'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout of plot\n",
    "    fig.update_layout(\n",
    "        title=title_, height=500, width=1000,\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=16,\n",
    "        ),\n",
    "        margin=dict(\n",
    "            l=100, r=50,\n",
    "            t=100, b=50,\n",
    "            pad=0\n",
    "        )\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4edfae",
   "metadata": {},
   "source": [
    "### Feature Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3e3d0",
   "metadata": {},
   "source": [
    "#### Article Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80052869",
   "metadata": {},
   "source": [
    "We need a function to populate our scroll percentages and read times for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_id_read_scroll(dict_, res):\n",
    "    \"\"\" \n",
    "    Populates the dict if that article is present in another dict!\n",
    "    Keyword arguments:\n",
    "        dict_--  dict: to map articles to scroll/read\n",
    "        res -- dict: to map unique articles to scroll/read\n",
    "    Output: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Iterate through each pair of key and value\n",
    "    for k, v in zip(dict_.keys(), dict_.values()):\n",
    "        # Find if the key matches up to another dict and is not false\n",
    "        if (k in res.keys()) & (np.isnan(v) == False):\n",
    "            # Add that resulting value to our resulting dict\n",
    "            tmp_array = np.append(res[k], v)\n",
    "            res[k] = tmp_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab34220",
   "metadata": {},
   "source": [
    "#### User Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410efb7",
   "metadata": {},
   "source": [
    "These are all functions used for the User section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58511ee",
   "metadata": {},
   "source": [
    "##### Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc294745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_dict(list_, dict_):\n",
    "    \"\"\" \n",
    "    Populates the dict from list indices\n",
    "    Keyword arguments:\n",
    "        list_--  list\n",
    "        dict_ -- dict: \n",
    "    Output: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Iterate through each list index and append the index as a key \n",
    "    for idx in list_:\n",
    "        if idx not in dict_:\n",
    "            dict_[idx] = 1\n",
    "        else:\n",
    "            dict_[idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a94da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_map(list_):\n",
    "    \"\"\" \n",
    "    Maps the Week of Year to (Week 1, Week 2, etc)\n",
    "    Keyword arguments:\n",
    "        list_ -- list \n",
    "    Output: \n",
    "        res -- list\n",
    "    \"\"\"\n",
    "    # Weeks represented from dataset\n",
    "    weeks = [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
    "    # List of integer values 1-9\n",
    "    placeholder = [i for i in range(1, 9)]\n",
    "    # Dict to map weeks to placeholder\n",
    "    dict_ = {k: v for k, v in zip(weeks, placeholder)}\n",
    "    # Populate that will return the Weeks starting from Week 1, Week 2\n",
    "    res = []\n",
    "    for idx in list_:\n",
    "        res.append('Week ' + str(dict_[idx]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba9726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_dow_dict(dict_):\n",
    "    \"\"\" \n",
    "    Maps the DayofWeek from int to str\n",
    "    Keyword arguments:\n",
    "        dict_ -- dict: \n",
    "    Output: \n",
    "        res -- list\n",
    "    \"\"\"\n",
    "    # Str of days\n",
    "    str_dow = ['Monday', 'Tuesday', 'Wednesday',\n",
    "               'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    # Int of days\n",
    "    int_dow = [i for i in range(7)]\n",
    "    # Map int of days to str of days\n",
    "    dow_dict = {k: v for k, v in zip(int_dow, str_dow)}\n",
    "    # Return the str of day given the int day\n",
    "    res = {}\n",
    "    for keys in dict_.keys():\n",
    "        res[dow_dict[keys]] = dict_[keys]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ff55f",
   "metadata": {},
   "source": [
    "#### Topic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1700ea",
   "metadata": {},
   "source": [
    "Functions used in the Topic sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65e811",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_subset_topics(df_):\n",
    "    \"\"\" \n",
    "    Returns a list of unique topics in the dataframe\n",
    "    Keyword arguments:\n",
    "        df--  dataframe object\n",
    "    Output: \n",
    "        res -- list of strs\n",
    "    \"\"\"\n",
    "    # Create our result list\n",
    "    res = []\n",
    "    # Iterate through each index of topic and append unique topics\n",
    "    for index in df_['topics']:\n",
    "        for topic_ in index:\n",
    "            if topic_ not in res:\n",
    "                res.append(topic_)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abfcd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_article_id_scroll_read (dict_, res):\n",
    "    \"\"\" \n",
    "    Populates the dict if that article is present in another dict!\n",
    "    Keyword arguments:\n",
    "        dict_--  dict: to map articles to scroll/read\n",
    "        res -- dict: to map unique articles to scroll/read\n",
    "    Output: \n",
    "        res -- dict: to map unique articles to scroll/read\n",
    "    \"\"\"\n",
    "    # Iterate through each pair of key and value\n",
    "    for k,v in zip(dict_.keys(), dict_.values()):\n",
    "        # If the key matches append that value\n",
    "        if (k in res.keys()):\n",
    "            tmp_array= np.append(res[k],v)\n",
    "            res[k] = tmp_array\n",
    "        # If the key is not present make an empty list for that key\n",
    "        if (k not in res.keys()):\n",
    "            res[k] = []\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9544ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_plot_col(dict_col_, list_category):\n",
    "    \"\"\" \n",
    "    Assigns a col number for the subplot given a key\n",
    "    Keyword arguments:\n",
    "        dict_col --  dict: to map category to col_num \n",
    "        list_category -- list: \n",
    "    Output: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Iterate thrugh the list of categories and assign a row number\n",
    "    for num, category_ in zip(range(0, len(list_category)), list_category):\n",
    "        # Even\n",
    "        if num % 2 == 0:\n",
    "            dict_col_[category_] = 1\n",
    "        # Odd\n",
    "        else:\n",
    "            dict_col_[category_] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3805674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_plot_row(dict_row_, list_category):\n",
    "    \"\"\" \n",
    "    Assigns a row number for the subplot given a key\n",
    "    Keyword arguments:\n",
    "        dict_row --  dict: to map category to row_num \n",
    "        list_category -- list: \n",
    "    Output: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Iterate through a loop and assign the row number of a category\n",
    "    # Instantiate counter and initial row number\n",
    "    counter = 0\n",
    "    row_num = 1\n",
    "    # Iterate through the loop. Expected behavior row_nums = [11 22 33 44 etc]\n",
    "    while counter < len(list_category):\n",
    "        num_ = 0\n",
    "        while (num_ < 2) & (counter < len(list_category)):\n",
    "            category_ = list_category[counter]\n",
    "            dict_row_[category_] = row_num\n",
    "            num_ += 1\n",
    "            counter += 1\n",
    "        row_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def row_num(dict_, key) -> None:\n",
    "        \"\"\" \n",
    "        Returns the row number of a given category\n",
    "        Keyword arguments:\n",
    "            dict_ -- row dict to map category to row_num\n",
    "            key -- dict.keys\n",
    "        Output: \n",
    "            None\n",
    "        \"\"\"\n",
    "        return dict_[key]\n",
    "    \n",
    "    def col_num(dict_, key) -> None:\n",
    "        \"\"\" \n",
    "        Returns the col number of a given category\n",
    "        Keyword arguments:\n",
    "            dict_ -- col dict to map category to col_num\n",
    "            key -- dict.keys\n",
    "        Output: \n",
    "            None\n",
    "        \"\"\"\n",
    "        return dict_[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_feature_bar_distribution(\n",
    "    df_, feature_,\n",
    "    topic_list_, yrange,\n",
    "    subplot_titles_, xaxis_title,\n",
    "    yaxis_title, title_,\n",
    "    height_, width_\n",
    ") -> 'Graph':\n",
    "    \"\"\" \n",
    "    Plot of topic distribution in respect to which feature of the dataframe was given.\n",
    "    Keyword arguments:\n",
    "        df_ -- dataframe object\n",
    "        feature_ -- str \n",
    "        topic_list -- list of strs: ['Blah', 'Blah']\n",
    "        yrange -- list of ints: [0, 5]\n",
    "        subplot_titles -- list of strs: ['Blah', 'Blah']\n",
    "        xaxis_title -- str\n",
    "        yaxis_title -- str\n",
    "        title_ -- str\n",
    "        height_ -- int\n",
    "        width_ -- int\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "    # Assign tmp_df based on feature\n",
    "    # Age feature is a string and the Null values contain <NA>\n",
    "    if feature_ == 'age':\n",
    "        tmp_df = df_[df_['age'] != '<NA>']\n",
    "    else:\n",
    "        tmp_df = df_[~df_[feature_].isnull()]\n",
    "\n",
    "    # List of categories sorted in order\n",
    "    categories = [d for d in tmp_df[feature_].unique()]\n",
    "    categories.sort()\n",
    "\n",
    "    # Make subplots need to figure out number of columns and rows:\n",
    "    # Instantiate dicts\n",
    "    dict_col = {}\n",
    "    dict_row = {}\n",
    "    # Populate our column and row dicts\n",
    "    assign_plot_col(dict_col_=dict_col, list_category=categories)\n",
    "    assign_plot_row(dict_row_=dict_row, list_category=categories)\n",
    "    # Number of total rows\n",
    "    rows_ = -(-len(categories) // 2)\n",
    "\n",
    "    # Make subplots object\n",
    "    fig = make_subplots(\n",
    "        rows=rows_, cols=2,\n",
    "        subplot_titles=subplot_titles_, shared_yaxes=True,\n",
    "        x_title=xaxis_title, y_title=yaxis_title,\n",
    "        vertical_spacing=0.2\n",
    "    )\n",
    "\n",
    "    # Iterate through each category and assign the correct subplot!\n",
    "    for idx, category_ in enumerate(categories):\n",
    "        # Find the subset of the data with that device\n",
    "        subset_df = tmp_df[tmp_df[feature_] == category_]\n",
    "        # Create a dict object with 0 counts for all topics\n",
    "        tmp_dict = {k: 0 for k in topic_list_}\n",
    "        for i in subset_df.index:\n",
    "            for j in range(0, len(subset_df['topics'][i])):\n",
    "                # Find that index\n",
    "                tmp_topic = subset_df['topics'][i][j]\n",
    "                # Enumerate\n",
    "                tmp_dict[tmp_topic] += 1\n",
    "        # Sort the dictionary\n",
    "        tmp_dict = dict(\n",
    "            sorted(tmp_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "        # Create our indices and values objects to insert into our plot\n",
    "        indices = [x for x in tmp_dict.keys()][0:5]\n",
    "        values = [y for y in tmp_dict.values()][0:5]\n",
    "        # Add our trace object\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=indices, y=values,\n",
    "                name=str(category_)\n",
    "            ),\n",
    "            row=col_num(dict_=dict_row, key=category_),\n",
    "            col=col_num(dict_=dict_col, key=category_)\n",
    "        )\n",
    "\n",
    "    # Update axis properties\n",
    "    # yaxes\n",
    "    fig.update_yaxes(\n",
    "        range=yrange, type=\"log\",\n",
    "    )\n",
    "    # xaxes\n",
    "    fig.update_xaxes(\n",
    "        tickfont=dict(\n",
    "            size=11, family='Courier', color='black'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout of plot\n",
    "    fig.update_layout(\n",
    "        title=title_, height=height_,\n",
    "        width=width_, font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=14,\n",
    "        ),\n",
    "        margin=dict(\n",
    "            l=100, r=50,\n",
    "            t=100, b=50,\n",
    "            pad=0)\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd1384",
   "metadata": {},
   "source": [
    "#### Activity Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7d449f",
   "metadata": {},
   "source": [
    "Functions used for the activity section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832af95e",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_hourly_activity_feature_bar_distribution(\n",
    "    df_, feature_,\n",
    "    yrange, subplot_titles_,\n",
    "    title_,\n",
    "    height_, width_\n",
    ") -> 'Graph':\n",
    "    \"\"\" \n",
    "    Plot of daily/hourly distribution in respect to which feature of the dataframe was given.\n",
    "    Keyword arguments:\n",
    "        df_ -- dataframe object\n",
    "        feature_ -- str \n",
    "        yrange -- list of ints: [0, 5]\n",
    "        subplot_titles -- list of strs: ['Blah', 'Blah']\n",
    "        title_ -- str\n",
    "        height_ -- int\n",
    "        width_ -- int\n",
    "    Output: \n",
    "        Plotly graph object!\n",
    "    \"\"\"\n",
    "    # Assign tmp_df based on feature\n",
    "    # Age feature is a string and the Null values contain <NA>\n",
    "    if feature_ == 'age':\n",
    "        tmp_df = df_[df_['age'] != '<NA>']\n",
    "    else:\n",
    "        tmp_df = df_[~df_[feature_].isnull()]\n",
    "\n",
    "    # List of categories sorted in order\n",
    "    categories = [d for d in tmp_df[feature_].unique()]\n",
    "    categories.sort()\n",
    "\n",
    "    # Add a color for each category\n",
    "    colors_ = [\n",
    "    'slateblue', 'seagreen', 'tomato', 'sienna', 'silver',\n",
    "    'skyblue', 'sandybrown', 'slategray', 'snow', 'springreen'\n",
    "             ][0:len(categories)]\n",
    "\n",
    "    # Make subplots object\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=subplot_titles_,\n",
    "        y_title='Count',\n",
    "        vertical_spacing=0.2\n",
    "    )\n",
    "    # Iterate through each category and assign the correct subplot!\n",
    "    for idx, category_ in enumerate(categories):\n",
    "        # Find the subset of the data with that device\n",
    "        subset_df = tmp_df[tmp_df[feature_] == category_]\n",
    "\n",
    "        # Create a dict object with 0 counts for all topics\n",
    "        subset_daily_activity = {}\n",
    "        subset_hourly_activity = {}\n",
    "        for i in subset_df.index:\n",
    "            # Get the date and time from that timestamp\n",
    "            tmp_timestamp = subset_df['impression_time'][i]\n",
    "            tmp_datetime = tmp_timestamp\n",
    "            tmp_date = tmp_datetime.date()\n",
    "            tmp_time = tmp_datetime.time()\n",
    "            tmp_hour = tmp_time.hour\n",
    "\n",
    "            # Daily Activity\n",
    "            if tmp_date not in subset_daily_activity:\n",
    "                subset_daily_activity[tmp_date] = 0\n",
    "            else:\n",
    "                subset_daily_activity[tmp_date] += 1\n",
    "\n",
    "            # Convert hour into a string\n",
    "            if tmp_hour > 9:\n",
    "                tmp_time = str(tmp_hour) + ':00'\n",
    "            else:\n",
    "                tmp_time = \"0\" + str(tmp_hour) + ':00'\n",
    "\n",
    "            # Hourly Activity\n",
    "            if tmp_time not in subset_hourly_activity:\n",
    "                subset_hourly_activity[tmp_time] = 0\n",
    "            else:\n",
    "                subset_hourly_activity[tmp_time] += 1\n",
    "\n",
    "        # Sort by dates\n",
    "        subset_daily_activity = dict(\n",
    "            sorted(subset_daily_activity.items())\n",
    "        )\n",
    "\n",
    "        # Daily Activity Plot\n",
    "        indices = [x for x in subset_daily_activity.keys()]\n",
    "        values = [y for y in subset_daily_activity.values()]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=indices, y=values,\n",
    "                name='Daily ' + str(category_), mode='lines+markers+text',\n",
    "                marker = dict(\n",
    "                    color = colors_[idx]\n",
    "                    )\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        # Hourly Activity\n",
    "        subset_hourly_activity = dict(\n",
    "            sorted(subset_hourly_activity.items())\n",
    "        )\n",
    "\n",
    "        indices = [x for x in subset_hourly_activity.keys()]\n",
    "        values = [y for y in subset_hourly_activity.values()]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=indices, y=values,\n",
    "                name='Hourly ' + str(category_), mode='lines+markers+text',\n",
    "                marker = dict(\n",
    "                    color = colors_[idx]\n",
    "                    )\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "    # Update axis properties\n",
    "    # yaxes\n",
    "    fig.update_yaxes(type='log',\n",
    "                     range=yrange,\n",
    "                     )\n",
    "    # xaxes\n",
    "    fig.update_xaxes(\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"<b>Date<b>\",\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"<b>Hour<b>\",\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # Update layout of plot\n",
    "    fig.update_layout(\n",
    "        title=title_, height=height_,\n",
    "        width=width_, font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=14,\n",
    "        ),\n",
    "        margin=dict(\n",
    "            l=100, r=50,\n",
    "            t=100, b=50,\n",
    "            pad=0)\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c935b234",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52407e",
   "metadata": {},
   "source": [
    "We aim to gain insights into which features we can utilize for our recommendation system.\n",
    "\n",
    "Questions:\n",
    "1. Explore the following features.\n",
    "    - Article\n",
    "    - User\n",
    "    - Session\n",
    "    - Topic\n",
    "    - Devices\n",
    "    - Subscriber vs Non-Subscriber\n",
    "    - Gender\n",
    "    - Ages\n",
    "    - Postcodes\n",
    "\n",
    "2. What are features that describe an article?\n",
    "    - Topic\n",
    "    - Read Time\n",
    "    - Scroll Percentage\n",
    "    - Page Views\n",
    "    - How do the features above relate to others?\n",
    "\n",
    "4. Describe the activity of our users? Subset it across our categorical features such as ages, devices, gender, postcodes, etc.\n",
    "    - Daily\n",
    "    - Hourly\n",
    "    - Weekly\n",
    "    - Day of the week\n",
    "5. Describe the topic distribution across our categorical features such as ages, devices, gender, postcodes, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b676b",
   "metadata": {},
   "source": [
    "### Overall Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d72253",
   "metadata": {},
   "source": [
    "#### Number of Impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c533c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Impressions\n",
    "single_subset_bar(df_=df, feature_='impression_id',\n",
    "                  xaxis_title='Number of Impressions', yrange=[0, 80000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce973c6",
   "metadata": {},
   "source": [
    "#### Distribution of Read Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce66858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Read Times\n",
    "single_subset_feature_visualization(\n",
    "    df_=df, feature_='read_time', data_title='All Impressions',\n",
    "    feature_title='Read Time(s)', histogram_xaxis_title='Read Time(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99341fb",
   "metadata": {},
   "source": [
    "#### Distribution of Scroll Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94105522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Scroll Percentages\n",
    "single_subset_feature_visualization(\n",
    "    df_=df, feature_='scroll_percentage', data_title='All Impressions',\n",
    "    feature_title='Scroll Percentage(%)', histogram_xaxis_title='Scroll Percentage(%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e913a",
   "metadata": {},
   "source": [
    "### Article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23a4e1",
   "metadata": {},
   "source": [
    "#### Number of Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb64116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Number of Articles\n",
    "single_subset_bar(df_ = df, feature_ = 'article_id', xaxis_title = 'Number of Articles', yrange = [0, 2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b6ce1",
   "metadata": {},
   "source": [
    "#### Number of articles clicked in a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ca0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique articles are clicked in a session?\n",
    "\n",
    "# Group by sessions and get the article ids\n",
    "tmp_aps = df.groupby('session_id')['article_id'].apply(list)\n",
    "\n",
    "# Create a dict to store the count of articles per session\n",
    "articles_per_session = {k: 0 for k in range(1, 20)}\n",
    "\n",
    "# Iterate through our list previously, and record the number of articles in a session to our res dict\n",
    "for i in tmp_aps:\n",
    "    num_articles = len(i)\n",
    "    articles_per_session[num_articles] += 1\n",
    "\n",
    "# Set as our indices / values for plot\n",
    "indices = [k for k in articles_per_session.keys()]\n",
    "values = [k for k in articles_per_session.values()]\n",
    "\n",
    "# Plot\n",
    "plot_bar(\n",
    "    indices_=indices, values_=values,\n",
    "    yrange_=[0, 5], xaxis_title='Number of Articles ',\n",
    "    yaxis_title='Count', title_='<b> Number of Articles clicked in a session<b>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f9c3a",
   "metadata": {},
   "source": [
    "#### Read Time and Scroll Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average readtime and scroll percentages for all articles!\n",
    "\n",
    "# Unique User Ids\n",
    "unique_user_ids = df['user_id'].values[0:1000]\n",
    "# We take the set because the scroll, article per user is joined in a list for every user id (so just take the set of it!)\n",
    "unique_user_ids = set(unique_user_ids)\n",
    "# Unique Article Ids\n",
    "unique_article_ids = df['article_id'].unique()\n",
    "unique_article_ids = unique_article_ids[~np.isnan(unique_article_ids)]\n",
    "# Create dictionaries\n",
    "unique_article_read = {k: [0] for k in unique_article_ids}\n",
    "unique_article_read_avg = {k: [0] for k in unique_article_ids}\n",
    "unique_article_scroll = {k: [0] for k in unique_article_ids}\n",
    "unique_article_scroll_avg = {k: [0] for k in unique_article_ids}\n",
    "\n",
    "# Iterate across each user id\n",
    "for id in unique_user_ids:\n",
    "    # Get the subset of that user id\n",
    "    tmp_df = df[df['user_id'] == id]\n",
    "    # Now lets go through each scroll and article\n",
    "    indices = np.array(tmp_df.index)\n",
    "    for i in indices:\n",
    "        tmp_dict = {}\n",
    "        # Select the scroll / article of that indice and\n",
    "        tmp_read = tmp_df['read_time_fixed'][i]\n",
    "        tmp_article = tmp_df['article_id_fixed'][i]\n",
    "        tmp_scroll = tmp_df['scroll_percentage_fixed'][i]\n",
    "        # Create list objects for article, read, scroll\n",
    "        read = [x for x in tmp_read]\n",
    "        scroll = [x for x in tmp_scroll]\n",
    "        articles = [np.int64(x) for x in tmp_article]\n",
    "        # Populate our unique_article_read dictionary based on the results found in our previous list objects\n",
    "        tmp_articles_read = {k: v for k, v in zip(articles, read)}\n",
    "        article_id_read_scroll(tmp_articles_read, unique_article_read)\n",
    "        # Populate our unique_article_scroll dictionary based on the results found in our previous list objects\n",
    "        tmp_articles_scroll = {k: v for k, v in zip(articles, scroll)}\n",
    "        article_id_read_scroll(tmp_articles_scroll, unique_article_scroll)\n",
    "\n",
    "# Get the average scroll percentage and read times for each article\n",
    "for k, v in zip(unique_article_read.keys(), unique_article_read.values()):\n",
    "    unique_article_read_avg[k] = np.mean(v)\n",
    "for k, v in zip(unique_article_scroll.keys(), unique_article_scroll.values()):\n",
    "    unique_article_scroll_avg[k] = np.mean(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d48fb8b",
   "metadata": {},
   "source": [
    "#### Read Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993bfafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Read Times for each Article\n",
    "## Indices / Values\n",
    "indices = ['<b>All Unique Articles<b>']\n",
    "values = [x for x in unique_article_read_avg.values()]\n",
    "## Plot\n",
    "plot_box(\n",
    "    indices_=indices, values_=[values],\n",
    "    yrange_=[0, 3], xaxis_title='',\n",
    "    yaxis_title='Read Time(s)', title_='<b> Distributions of Read Time Across All Articles<b>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64daaf77",
   "metadata": {},
   "source": [
    "#### Scroll Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Scroll Percentages for each Article\n",
    "## Indices / Values\n",
    "indices = ['<b>All Unique Articles<b>']\n",
    "values = [x for x in unique_article_scroll_avg.values()]\n",
    "## Plot\n",
    "plot_box(\n",
    "    indices_=indices, values_=[values],\n",
    "    yrange_=[0, 2], xaxis_title='',\n",
    "    yaxis_title='Scroll Percentage (%)', title_='<b> Distributions of Scroll Percentage Across All Articles!<b>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668d320",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d88858",
   "metadata": {},
   "source": [
    "#### Number of Users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Number of Users\n",
    "single_subset_bar(df_ = df, feature_ = 'user_id', xaxis_title = 'Number of Users', yrange = [0, 11000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361ef1f1",
   "metadata": {},
   "source": [
    "#### Daily User growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the daily user growth\n",
    "unique_user_ids = df['user_id'].unique()\n",
    "\n",
    "# Create dictionaries\n",
    "unique_users_daily_growth_freq= {}\n",
    "unique_users_hourly_freq = {}\n",
    "unique_users_dayofweek_freq = {}\n",
    "unique_users_weekly_freq = {}\n",
    "\n",
    "# Iterate through each user id and record the number of unique users present!\n",
    "for id in unique_user_ids[0:1000]:\n",
    "    # Get the subset of that user id\n",
    "    tmp_df = df[df['user_id'] == id]\n",
    "    # Get the first index of that impression time\n",
    "    first_index = tmp_df['impression_time_fixed'].index[0]\n",
    "    # Record that join_date \n",
    "    tmp_datetime = pd.DatetimeIndex(tmp_df['impression_time_fixed'][first_index])\n",
    "    tmp_date = tmp_datetime[0].date()\n",
    "    join_date = tmp_date\n",
    "    # Populate our unique_user_daily_growth\n",
    "    if join_date not in unique_users_daily_growth_freq:\n",
    "        unique_users_daily_growth_freq[join_date] = 1\n",
    "    else:\n",
    "        unique_users_daily_growth_freq[join_date] +=1\n",
    "\n",
    "# Sort our dict\n",
    "unique_users_daily_growth_freq = dict(sorted(unique_users_daily_growth_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bafa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily User Growth\n",
    "\n",
    "# Indices / Values for Plot\n",
    "indices = [x for x in unique_users_daily_growth_freq.keys()]\n",
    "values = [x for x in unique_users_daily_growth_freq.values()]\n",
    "# Plot\n",
    "plot_bar(indices_=indices, values_=values, yrange_=[\n",
    "         0, 3], xaxis_title='<b>Dates<b>', yaxis_title='<b>Count<b>', title_='<b>Daily User Growth<b>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6f358",
   "metadata": {},
   "source": [
    "#### Read Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Time per User\n",
    "\n",
    "# Group by User and Read Time\n",
    "tmp_user_df = pd.DataFrame(data=df.groupby(by='user_id')[\n",
    "                           'read_time'].mean(), columns=['read_time'])\n",
    "# Plot\n",
    "single_subset_feature_visualization(\n",
    "    df_=tmp_user_df,  feature_='read_time',\n",
    "    data_title='Unique Users', feature_title ='Read Time(s)',\n",
    "    histogram_xaxis_title = 'Read Time(s)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4424d9e",
   "metadata": {},
   "source": [
    "#### Scroll Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bab00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll Percentage per User\n",
    "\n",
    "# Group by User and Scroll Percentage\n",
    "tmp_user_df = pd.DataFrame(data=df.groupby(by='user_id')[\n",
    "                           'scroll_percentage'].mean(), columns=['scroll_percentage'])\n",
    "# Plot\n",
    "single_subset_feature_visualization(\n",
    "    df_=tmp_user_df,  feature_='scroll_percentage',\n",
    "    data_title='Unique Users', feature_title ='Scroll Percentage(%)',\n",
    "    histogram_xaxis_title = 'Scroll Percentage(%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec7344e",
   "metadata": {},
   "source": [
    "#### User Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the daily, hourly, weekly, dayofweek activity across all users\n",
    "\n",
    "# Get all unique ids in a list\n",
    "unique_user_ids = df['user_id'].unique()[0:1000]\n",
    "\n",
    "# Create dictionaries\n",
    "unique_users_daily_freq = {}\n",
    "unique_users_hourly_freq = {}\n",
    "unique_users_dayofweek_freq = {}\n",
    "unique_users_weekly_freq = {}\n",
    "\n",
    "# Iterate through each user id\n",
    "for id in unique_user_ids:\n",
    "    # Get the subset of that user id\n",
    "    tmp_df = df[df['user_id'] == id]\n",
    "\n",
    "    # Now lets go through each and populate the unique dates, hours and day of the week for each user\n",
    "    dates = []\n",
    "    hours = []\n",
    "    dayofweek = []\n",
    "    week = []\n",
    "    indices = np.array(tmp_df.index)\n",
    "\n",
    "    # Iterate through each index\n",
    "    for i in indices:\n",
    "        # Store the date, time, dayofweek, and week number\n",
    "        tmp_datetime = pd.DatetimeIndex(tmp_df['impression_time_fixed'][i])\n",
    "        tmp_date = tmp_datetime.date\n",
    "        tmp_time = tmp_datetime.time\n",
    "        tmp_dayofweek = tmp_datetime.weekday\n",
    "        tmp_week = tmp_datetime.isocalendar().week\n",
    "        # Append our dates, hours, dayofweek, week number\n",
    "        for j, k, l, m in zip(tmp_date, tmp_time, tmp_dayofweek, tmp_week):\n",
    "            dates.append(j)\n",
    "            hours.append(k)\n",
    "            dayofweek.append(l)\n",
    "            week.append(m)\n",
    "\n",
    "    # Get rid of duplicate values\n",
    "    unique_dates = list(set(dates))\n",
    "    unique_hours = list(set(hours))\n",
    "    unique_dayofweek = list(set(dayofweek))\n",
    "    unique_week = list(set(week))\n",
    "\n",
    "    # Convert to string\n",
    "    unique_hours = [x.hour for x in unique_hours]\n",
    "    unique_hours = [str(i) + ':00' if i > 9 else str(0) +\n",
    "                    str(i) + ':00' for i in unique_hours]\n",
    "\n",
    "    # Convert the week int to mapping from 1++\n",
    "    unique_week = weekly_map(unique_week)\n",
    "\n",
    "    # Populate dicts\n",
    "    populate_dict(list_=unique_dates, dict_=unique_users_daily_freq)\n",
    "    populate_dict(list_=unique_hours, dict_=unique_users_hourly_freq)\n",
    "    populate_dict(list_=unique_dayofweek, dict_=unique_users_dayofweek_freq)\n",
    "    populate_dict(list_=unique_week, dict_=unique_users_weekly_freq)\n",
    "\n",
    "\n",
    "# Sort our dicts\n",
    "unique_users_daily_freq = dict(sorted(unique_users_daily_freq.items()))\n",
    "unique_users_hourly_freq = dict(sorted(unique_users_hourly_freq.items()))\n",
    "\n",
    "# Sort by integers for day of the week and then lets change the dict from int to str\n",
    "unique_users_dayofweek_freq = dict(sorted(unique_users_dayofweek_freq.items()))\n",
    "unique_users_dayofweek_freq = int_dow_dict(unique_users_dayofweek_freq)\n",
    "\n",
    "unique_users_weekly_freq = dict(sorted(unique_users_weekly_freq.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d544d44",
   "metadata": {},
   "source": [
    "##### Daily User Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7919508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily User Activity\n",
    "\n",
    "## Indices / Values for Plot\n",
    "indices = [x for x in unique_users_daily_freq.keys()]\n",
    "values = [x for x in unique_users_daily_freq.values()]\n",
    "\n",
    "## Plot\n",
    "plot_scatter(\n",
    "    indices_=indices, values_=values,\n",
    "    yrange_=[200, 900], xaxis_title='Date',\n",
    "    yaxis_title='Active Users', title_='<b>Daily Active Users<b>'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f0156b",
   "metadata": {},
   "source": [
    "##### Hourly User Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly User Activity\n",
    "\n",
    "## Indices / Values for Plot\n",
    "indices = [x for x in unique_users_hourly_freq.keys()]\n",
    "values = [x for x in unique_users_hourly_freq.values()]\n",
    "\n",
    "## Plot\n",
    "plot_scatter(\n",
    "    indices_ = indices , values_ = values,\n",
    "    yrange_ = [0, 20000], xaxis_title = 'Hour',\n",
    "    yaxis_title= 'Active Users', title_ = '<b>Hourly Active Users<b>'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cef0a4",
   "metadata": {},
   "source": [
    "##### Weekly User Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e5d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly User Activity\n",
    "\n",
    "## Indices / Values for Plot\n",
    "indices = [x for x in unique_users_weekly_freq.keys()]\n",
    "values = [x for x in unique_users_weekly_freq.values()]\n",
    "\n",
    "## Plot\n",
    "plot_bar(\n",
    "    indices_ = indices, values_ = values,\n",
    "    yrange_ = [0, 3.5], xaxis_title = 'Week',\n",
    "    yaxis_title= 'Active Users', title_ = '<b> Weekly Active Users <b>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b047d88",
   "metadata": {},
   "source": [
    "##### Day Of The Week User Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day Of The Week Activity\n",
    "\n",
    "## Indices / Values for Plot\n",
    "indices = [x for x in unique_users_dayofweek_freq.keys()]\n",
    "values = [x for x in unique_users_dayofweek_freq.values()]\n",
    "\n",
    "## Plot\n",
    "plot_bar(\n",
    "    indices_ = indices, values_ = values,\n",
    "    yrange_ = [0, 3.5], xaxis_title = 'Day',\n",
    "    yaxis_title= 'Active Users', title_ = '<b> Day of the Week Activity  <b>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812afcd3",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d54dba",
   "metadata": {},
   "source": [
    "#### Number of Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5866c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toal Number of Sessions\n",
    "single_subset_bar(df_=df, feature_='session_id',\n",
    "                  xaxis_title='Number of Sessions', yrange=[0, 40000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e07092",
   "metadata": {},
   "source": [
    "#### Daily Active Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638efd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique sessions per day\n",
    "\n",
    "# Make a copy of the dataframe and extract the time as a str\n",
    "copy_df = df.copy()\n",
    "copy_df['impression_time'] = copy_df['impression_time'].apply(\n",
    "    lambda x: x.date())\n",
    "\n",
    "# Group by the session ids with the impression time\n",
    "unique_sessions_per_day = copy_df.groupby(\n",
    "    by='session_id')['impression_time'].min()\n",
    "tmp_dau_df = pd.DataFrame(data=unique_sessions_per_day.values,\n",
    "                          index=unique_sessions_per_day.keys(), columns=['Session Dates'])\n",
    "\n",
    "# Plot\n",
    "multiple_subset_bar(\n",
    "    df_=tmp_dau_df, feature_='Session Dates',\n",
    "    yrange=[0, 4.5], xaxis_title = 'Session Dates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76c067",
   "metadata": {},
   "source": [
    "#### Read Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Time per Session\n",
    "## Group by session ids and read_time \n",
    "tmp_session_df = pd.DataFrame(data=df.groupby(by='session_id')[\n",
    "                              'read_time'].mean(), columns=['read_time'])\n",
    "## Plot\n",
    "single_subset_feature_visualization(\n",
    "    df_=tmp_session_df,  feature_='read_time',\n",
    "    data_title='Unique Sessions', feature_title = 'Read Time(s)',\n",
    "    histogram_xaxis_title ='Read Time(s)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d99ce7",
   "metadata": {},
   "source": [
    "#### Scroll Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a83b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll Percentage per Session\n",
    "## Group by session ids and scroll percentage\n",
    "tmp_session_df = pd.DataFrame(data=df.groupby(by='session_id')[\n",
    "                              'scroll_percentage'].mean(), columns=['scroll_percentage'])\n",
    "## Plot\n",
    "single_subset_feature_visualization(\n",
    "    df_=tmp_session_df,  feature_='scroll_percentage',\n",
    "    data_title='Unique Sessions', feature_title = 'Scroll Percentage(%)',\n",
    "    histogram_xaxis_title ='Scroll Percentage(%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae85ec3",
   "metadata": {},
   "source": [
    "### Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd25db",
   "metadata": {},
   "source": [
    "#### Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Topics!\n",
    "# Unique Topics\n",
    "topic_list = unique_subset_topics(df)\n",
    "# Plot\n",
    "tmp_topic_df = pd.DataFrame(data=topic_list, columns=['topics'])\n",
    "\n",
    "single_subset_bar(df_=tmp_topic_df, feature_='topics',\n",
    "                  xaxis_title='Number of Topics', yrange=[0, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the frequency of topics across unique users, readtimes across topics, and scroll percentages across those topics\n",
    "\n",
    "# Get all unique ids in a list\n",
    "unique_user_ids = df['user_id'].values[0:1000]\n",
    "\n",
    "# Create dictionaries\n",
    "unique_users_topics_freq = {}\n",
    "unique_topic_scroll_freq = {}\n",
    "unique_topic_read_freq = {}\n",
    "\n",
    "# Iterate through each user id and record the topics viewed!\n",
    "for id in unique_user_ids:\n",
    "    # Get the subset of that user id\n",
    "    tmp_df = df[df['user_id'] == id]\n",
    "    # Now lets go through each topic\n",
    "    indices = np.array(tmp_df.index)\n",
    "    for i in indices:\n",
    "        # Record the topic, scroll percentage and read_time for each index\n",
    "        tmp_topics = tmp_df['topics'][i]\n",
    "        tmp_scroll = tmp_df['scroll_percentage'][i]\n",
    "        tmp_read = tmp_df['read_time'][i]\n",
    "        topics = [x for x in tmp_topics]\n",
    "        scroll = [tmp_scroll]\n",
    "        read = [tmp_read]\n",
    "\n",
    "    # Find the average scroll percentages across each topic  (Can be related to whether a topic doesnt require too much reading has visualizations)\n",
    "    # Look at article_id for whichever topics the article is included in add that scroll percentage\n",
    "        tmp_topic_scroll = {k: v for k, v in zip(topics, scroll)}\n",
    "        unique_topic_scroll_freq = topics_article_id_scroll_read(\n",
    "            tmp_topic_scroll, unique_topic_scroll_freq)\n",
    "\n",
    "    # Find the average read time across each topic\n",
    "    # Look at article_id for whichever topics the article is included in add that readtime\n",
    "        tmp_topic_read = {k: v for k, v in zip(topics, read)}\n",
    "        unique_topic_read_freq = topics_article_id_scroll_read(\n",
    "            tmp_topic_read, unique_topic_read_freq)\n",
    "\n",
    "    # Unique User Topics\n",
    "    # Get rid of duplicate values\n",
    "    unique_topics = list(set(topics))\n",
    "\n",
    "    # Populate our dict\n",
    "    populate_dict(unique_topics, unique_users_topics_freq)\n",
    "\n",
    "\n",
    "# Sort the dictionaries\n",
    "sorted_topic_freq = dict(\n",
    "    sorted(unique_users_topics_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Find the average read times across each topic\n",
    "unique_topic_read_avg_freq = {k: round(np.nanmean(v), 2) for k, v in zip(\n",
    "    unique_topic_read_freq.keys(), unique_topic_read_freq.values())}\n",
    "sorted_unique_topic_read_avg_freq = dict(\n",
    "    sorted(unique_topic_read_avg_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Sort the topics for distribution\n",
    "sorted_unique_topic_read_freq = dict(sorted(unique_topic_read_freq.items()))\n",
    "\n",
    "# Find the average scroll percentages across each topic\n",
    "unique_topic_scroll_avg_freq = {k: round(np.nanmean(v), 2) for k, v in zip(\n",
    "    unique_topic_scroll_freq.keys(), unique_topic_scroll_freq.values())}\n",
    "sorted_unique_topic_scroll_avg_freq = dict(\n",
    "    sorted(unique_topic_scroll_avg_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Sort the topics scroll pct for distribution\n",
    "sorted_unique_topic_scroll_freq = dict(\n",
    "    sorted(unique_topic_scroll_freq.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f54e8",
   "metadata": {},
   "source": [
    "#### Distribution of Topics across users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa6df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Topics across users!\n",
    "## Indices / Values for Plot\n",
    "indices = [x for x in sorted_topic_freq.keys()][0:10]\n",
    "values = [x for x in sorted_topic_freq.values()][0:10]\n",
    "\n",
    "## Plot\n",
    "plot_bar(\n",
    "    indices_=indices, values_=values,\n",
    "    yrange_=[0, 3], xaxis_title='Topics',\n",
    "    yaxis_title='Count', title_='<b> Top 10 Highest Topic Activity<b>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab41490",
   "metadata": {},
   "source": [
    "#### Read Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bea6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot of Read Time across Topics\n",
    "## Indices / Values for Plot\n",
    "indices = [x for x in sorted_unique_topic_read_avg_freq.keys()][0:5]\n",
    "values = [x for x in sorted_unique_topic_read_avg_freq.values()][0:5]\n",
    "## Plot\n",
    "plot_bar(\n",
    "    indices_ = indices, values_ = values,\n",
    "    yrange_ = [0, 3], xaxis_title = 'Topics',\n",
    "    yaxis_title= 'Read Time(s)', title_ = '<b> Top 5 Read Times across each Topics<b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot of Read Time across Topics\n",
    "## Indices / Values for Plot\n",
    "indices = [x for x in sorted_unique_topic_read_freq.keys()]\n",
    "values = [x for x in sorted_unique_topic_read_freq.values()]\n",
    "## Plot\n",
    "plot_box(\n",
    "    indices_ = indices, values_ = values,\n",
    "    yrange_ = [0, 3.5], xaxis_title = 'Topics',\n",
    "    yaxis_title= 'Read Time(s)', title_ = '<b> Distributions of Read Times across each Topic<b>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973adab",
   "metadata": {},
   "source": [
    "#### Scroll Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6732699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot of Scroll Percentage across Topics\n",
    "## Indices / Values for Plot\n",
    "indices = [x for x in sorted_unique_topic_scroll_avg_freq.keys()]\n",
    "values = [x for x in sorted_unique_topic_scroll_avg_freq.values()]\n",
    "## Plot\n",
    "plot_bar(\n",
    "    indices_ = indices, values_ = values,\n",
    "    yrange_ = [0, 2.5], xaxis_title = 'Topics',\n",
    "    yaxis_title= 'Scroll Percentage(%)', title_ = '<b> Average Scroll Percentage across each Topic<b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot of Scroll Percentage across Topics\n",
    "## Indices / Values for Plot\n",
    "indices = [x for x in sorted_unique_topic_scroll_freq.keys()]\n",
    "values = [x for x in sorted_unique_topic_scroll_freq.values()]\n",
    "## Plot\n",
    "plot_box(\n",
    "    indices_ = indices, values_ = values,\n",
    "    yrange_ = [0, 2.1], xaxis_title = 'Topics',\n",
    "    yaxis_title= 'Read Time(s)', title_ = '<b> Distributions of Read Times across each Topic<b>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97be17",
   "metadata": {},
   "source": [
    "#### Daily and Hourly Activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144c7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily and Hourly Activity across each Topic\n",
    "\n",
    "# Get all the unique topics\n",
    "topic_list = unique_subset_topics(df)\n",
    "unique_topics = sorted(topic_list)\n",
    "\n",
    "# Get the list of each unqiue topic in a specific session\n",
    "topics = df.groupby(by='session_id')['topics'].apply(list)\n",
    "\n",
    "# Get the list of each unique timestamp for these sessions\n",
    "timestamps = df.groupby(by='session_id')['impression_time'].apply(list)\n",
    "unique_dates = []\n",
    "\n",
    "# Create a list of hours in a str format\n",
    "unique_hours = [i for i in range(24)]\n",
    "unique_hours = [str(i) + ':00' if i > 9 else str(0) +\n",
    "                str(i) + ':00' for i in unique_hours]\n",
    "\n",
    "# Iterate through each timestamp\n",
    "for i in range(len(timestamps.values)):\n",
    "    # Iterate through each idx\n",
    "    for j in range(len(timestamps.values[i])):\n",
    "        # Assign datetime and date objects\n",
    "        tmp_datetime = timestamps.values[i][j]\n",
    "        tmp_date = tmp_datetime.date()\n",
    "        # if date not in unique dates, append\n",
    "        if tmp_date not in unique_dates:\n",
    "            unique_dates.append(tmp_date)\n",
    "\n",
    "# Sort dates\n",
    "unique_dates = sorted(unique_dates)\n",
    "\n",
    "# Instantiate dict objects with unique dates and unique key values set to 0\n",
    "unique_topic_daily_activity = {\n",
    "    k: {k: 0 for k in unique_dates} for k in unique_topics}\n",
    "unique_topic_hourly_activity = {\n",
    "    k: {k: 0 for k in unique_hours} for k in unique_topics}\n",
    "\n",
    "\n",
    "# Iterate through each session id\n",
    "for i in zip(range(len(topics.values))):\n",
    "    # Iterate through each index of nested list\n",
    "    for j, k in zip(range(0, len(topics.values[i][0])), range(0, len(i))):\n",
    "        tmp = topics.values[i][0][j]\n",
    "        # Assign a datetime and time object\n",
    "        tmp_datetime = timestamps.values[i][k]\n",
    "        tmp_date = tmp_datetime.date()\n",
    "        tmp_time = tmp_datetime.time()\n",
    "        tmp_hour = tmp_time.hour\n",
    "\n",
    "        # Convert hour into a string\n",
    "        if tmp_hour > 9:\n",
    "            tmp_time = str(tmp_hour) + ':00'\n",
    "\n",
    "        else:\n",
    "            tmp_time = \"0\" + str(tmp_hour) + ':00'\n",
    "\n",
    "        # Add to dictionary\n",
    "        unique_topic_daily_activity[tmp][tmp_date] += 1\n",
    "        unique_topic_hourly_activity[tmp][tmp_time] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e4838",
   "metadata": {},
   "source": [
    "##### Daily Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Activity of Topics \n",
    "activity_scatter(\n",
    "    dict_=unique_topic_daily_activity,  yrange_=[0, 2100],\n",
    "    xaxis_title='Dates', yaxis_title='Active Users', title_='<b> Daily Active Users per Topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03917388",
   "metadata": {},
   "source": [
    "##### Hourly Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fe30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly Activity of Topics \n",
    "activity_scatter(\n",
    "    dict_=unique_topic_hourly_activity,  yrange_=[0, 1000],\n",
    "    xaxis_title='Hourly', yaxis_title='Active Users', title_='<b> Hourly Active Users per Topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e4503e",
   "metadata": {},
   "source": [
    "### Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Devices\n",
    "multiple_subset_bar(df_=df, feature_='device_type', yrange=[0, 5], xaxis_title = 'Devices')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dffc83",
   "metadata": {},
   "source": [
    "#### Readtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d060cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(go.Contour(\n",
    "    z=[[10, 10.625, 12.5, 15.625, 20],\n",
    "       [5.625, 6.25, 8.125, 11.25, 15.625],\n",
    "       [2.5, 3.125, 5., 8.125, 12.5],\n",
    "       [0.625, 1.25, 3.125, 6.25, 10.625],\n",
    "       [0, 0.625, 2.5, 5.625, 10]],\n",
    "    colorscale=\"Cividis\",\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20604809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Time across Devices\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='device_type',\n",
    "    feature_2='read_time', feature_1_title='Devices',\n",
    "    feature_2_title='Read Time(s)', histogram_xaxis_title='Read Time(s)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e86ec",
   "metadata": {},
   "source": [
    "#### Scroll percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d7a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll Percentage across Devices\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='device_type',\n",
    "    feature_2='scroll_percentage', feature_1_title='Devices',\n",
    "    feature_2_title='Scroll Percentages(%)', histogram_xaxis_title='Scroll Percentages(%)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8ea32",
   "metadata": {},
   "source": [
    "#### Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Topics Per Device\n",
    "# Unique Topics\n",
    "topic_list = unique_subset_topics(df)\n",
    "unique_topics = sorted(topic_list)\n",
    "# Plot\n",
    "topic_feature_bar_distribution(\n",
    "    df_=df, feature_='device_type', yrange=[0, 4.5],\n",
    "    topic_list_=unique_topics, subplot_titles_=[\n",
    "        '<b>Desktop<b>', '<b>Mobile<b>', '<b>Tablet<b>'],\n",
    "    xaxis_title='<b>Topics<b>', yaxis_title='<b>Count<b>',\n",
    "    title_='<b>Topic Distribution Per Device<b>',\n",
    "    height_=750, width_=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6e44c",
   "metadata": {},
   "source": [
    "#### Daily/Hourly Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily and Hourly Activity across Devices\n",
    "daily_hourly_activity_feature_bar_distribution(\n",
    "    df_ = df, feature_ = 'device_type', yrange = [0, 4],\n",
    "    subplot_titles_ = ['<b>Daily<b>', '<b>Monthly<b>'],\n",
    "    title_ = '<b>Daily and Hourly Activity per Device<b>',\n",
    "    height_ = 750, width_ = 1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b7ff5",
   "metadata": {},
   "source": [
    "### If subscriber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2445ea77",
   "metadata": {},
   "source": [
    "#### Distribution of Subscribers vs Non-Subscribers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Subscribers vs Non-Subscribers\n",
    "multiple_subset_bar(\n",
    "    df_=df, feature_='is_subscriber',\n",
    "    yrange=[0, 5.5], xaxis_title = 'Subscriber vs Non-Subscribers'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76723f43",
   "metadata": {},
   "source": [
    "#### Read time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a41086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Times for Subscribers vs Non-Subscribers\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='is_subscriber',\n",
    "    feature_2='read_time', feature_1_title='Subscriber vs Non-Subscriber',\n",
    "    feature_2_title='Read Time(s)', histogram_xaxis_title='Read Time(s)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47680f96",
   "metadata": {},
   "source": [
    "#### Scroll percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e0a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll Percentages for Subscribers vs Non-Subscribers\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='is_subscriber',\n",
    "    feature_2='scroll_percentage', feature_1_title='Subscriber vs Non-Subscriber',\n",
    "    feature_2_title='Scroll Percentage(%)', histogram_xaxis_title='Scroll Percentage(%)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b096414c",
   "metadata": {},
   "source": [
    "#### Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e83855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Topics for Subscribers vs Non-Subscribers\n",
    "## Get all the unique topics\n",
    "topic_list = unique_subset_topics(df)\n",
    "unique_topics = sorted(topic_list)\n",
    "## Plot\n",
    "topic_feature_bar_distribution(\n",
    "    df_=df, feature_='is_subscriber', yrange=[0, 5],\n",
    "    topic_list_=unique_topics, subplot_titles_=['<b>False<b>', '<b>True<b>'],\n",
    "    xaxis_title='<b>Topics<b>', yaxis_title='<b>Count<b>',\n",
    "    title_='<b>Topic Distribution of Subscribers vs Non-Subscribers<b>',\n",
    "    height_=500, width_=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3ff67",
   "metadata": {},
   "source": [
    "#### Daily/Hourly Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284aee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Activity Users / Hourly Activity Users for Subscribers vs Non-Subscribers\n",
    "daily_hourly_activity_feature_bar_distribution(\n",
    "    df_ = df, feature_ = 'is_subscriber', yrange = [0, 4],\n",
    "    subplot_titles_ = ['<b>Daily<b>', '<b>Monthly<b>'],\n",
    "    title_ = '<b>Daily and Hourly Activity of Subscribers vs Non-Subscribers<b>',\n",
    "    height_ = 750, width_ = 1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469168b",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa327ef",
   "metadata": {},
   "source": [
    "#### Distribution of Genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7df9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Genders\n",
    "multiple_subset_bar(\n",
    "    df_=df, feature_='gender', yrange=[0, 4.5],\n",
    "    xaxis_title='Genders')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e0c923",
   "metadata": {},
   "source": [
    "#### Read time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Time across Genders\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='gender',\n",
    "    feature_2='read_time', feature_1_title='Gender',\n",
    "    feature_2_title='Read Time(s)', histogram_xaxis_title='Read Time(s)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd149a",
   "metadata": {},
   "source": [
    "#### Scroll percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373617e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll Percentage across Genders\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='gender',\n",
    "    feature_2='scroll_percentage', feature_1_title='Gender',\n",
    "    feature_2_title='Scroll Percentage(%)', histogram_xaxis_title='Scroll Percentage(%)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb1468",
   "metadata": {},
   "source": [
    "#### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Topics across Genders\n",
    "## Get all the unique topics\n",
    "topic_list = unique_subset_topics(df)\n",
    "unique_topics = sorted(topic_list)\n",
    "## Plot\n",
    "topic_feature_bar_distribution(\n",
    "    df_=df, feature_='gender', yrange=[0, 5],\n",
    "    topic_list_=unique_topics, subplot_titles_=['<b>Female<b>', '<b>Male<b>'],\n",
    "    xaxis_title='<b>Topics<b>', yaxis_title='<b>Count<b>',\n",
    "    title_='<b>Topic Distribution of Genders<b>',\n",
    "    height_=500, width_=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb16616",
   "metadata": {},
   "source": [
    "#### Daily/Hourly Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db72f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Activity Users / Hourly Activity Users across Genders\n",
    "daily_hourly_activity_feature_bar_distribution(\n",
    "    df_=df, feature_='gender', yrange=[0, 4],\n",
    "    subplot_titles_=['<b>Daily<b>', '<b>Monthly<b>'],\n",
    "    title_='<b>Daily and Hourly Activity of Genders<b>',\n",
    "    height_=750, width_=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e32b90",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c5c75",
   "metadata": {},
   "source": [
    "#### Age Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc785b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Ages\n",
    "multiple_subset_bar(\n",
    "    df_=df, feature_='age', yrange=[0, 3.5],\n",
    "    xaxis_title ='Age'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d84e0",
   "metadata": {},
   "source": [
    "#### Read Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Time across Ages\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='age',\n",
    "    feature_2='read_time', feature_1_title='Age',\n",
    "    feature_2_title='Read Time(s)', histogram_xaxis_title='Read Time(s)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3883ce0",
   "metadata": {},
   "source": [
    "#### Scroll Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll Percentages across Ages\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='age',\n",
    "    feature_2='scroll_percentage', feature_1_title='Age',\n",
    "    feature_2_title='Scroll Percent(%)', histogram_xaxis_title='Scroll Percentage(%)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa72d5e",
   "metadata": {},
   "source": [
    "#### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Topics across Ages\n",
    "## Get all the unique topics\n",
    "topic_list = unique_subset_topics(df)\n",
    "unique_topics = sorted(topic_list)\n",
    "## Plot\n",
    "topic_feature_bar_distribution(\n",
    "    df_=df, feature_='age', yrange=[0, 2.5],\n",
    "    topic_list_=unique_topics,\n",
    "    subplot_titles_=[\n",
    "        '<b>20-29<b>', '<b>30-39<b>', '<b>40-49<b>',\n",
    "        '<b>50-59<b>', '<b>60-69<b>', '<b>70-79<b>',\n",
    "        '<b>80-89<b>', '<b>90-99<b>'\n",
    "    ],\n",
    "    xaxis_title='<b>Topics<b>', yaxis_title='<b>Count<b>',\n",
    "    title_='<b>Topic Distribution of Age Groups<b>',\n",
    "    height_=1000, width_=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2106c5",
   "metadata": {},
   "source": [
    "#### Daily/Hourly Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41764352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Activity Users / Hourly Activity Users across Age\n",
    "daily_hourly_activity_feature_bar_distribution(\n",
    "    df_=df, feature_='age', yrange=[0, 2.5],\n",
    "    subplot_titles_=['<b>Daily<b>', '<b>Monthly<b>'],\n",
    "    title_='<b>Daily and Hourly Activity of Age Groups<b>',\n",
    "    height_=750, width_=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e40744",
   "metadata": {},
   "source": [
    "### Postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b31209f",
   "metadata": {},
   "source": [
    "#### Distribution of Post Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Postcodes. \n",
    "multiple_subset_bar(\n",
    "    df_=df, feature_='postcode',\n",
    "    yrange=[0, 3], xaxis_title ='Postcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5a212",
   "metadata": {},
   "source": [
    "#### Read Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6fd3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Time across Postcodes\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='postcode',\n",
    "    feature_2='read_time', feature_1_title='Postcodes',\n",
    "    feature_2_title='Read Time(s)', histogram_xaxis_title='Read Time(s)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13bde99",
   "metadata": {},
   "source": [
    "#### Scroll Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43deafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll Percentages across Postcodes\n",
    "multiple_subset_feature_visualization(\n",
    "    df_=df,  feature_1='postcode',\n",
    "    feature_2='scroll_percentage', feature_1_title='Postcode',\n",
    "    feature_2_title='Scroll Percent(%)', histogram_xaxis_title='Scroll Percentage(%)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f742f798",
   "metadata": {},
   "source": [
    "#### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7018e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Topics across Postcodes\n",
    "## Get all the unique topics\n",
    "topic_list = unique_subset_topics(df)\n",
    "unique_topics = sorted(topic_list)\n",
    "## Plot\n",
    "topic_feature_bar_distribution(\n",
    "    df_=df, feature_='postcode', yrange=[0, 2.5],\n",
    "    topic_list_=unique_topics,\n",
    "    subplot_titles_=[\n",
    "        '<b>Big City<b>', '<b>Metropolitan<b>', '<b>Municiplaity<b>',\n",
    "        '<b>Provincial<b>', '<b>Rural District<b>'\n",
    "    ],\n",
    "    xaxis_title='<b>Topics<b>', yaxis_title='<b>Count<b>',\n",
    "    title_='<b>Topic Distribution per Postcodes<b>',\n",
    "    height_=850, width_=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53434a",
   "metadata": {},
   "source": [
    "#### Daily/Hourly Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af96cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Activity Users / Hourly Activity Users across Postcodes\n",
    "daily_hourly_activity_feature_bar_distribution(\n",
    "    df_=df, feature_='postcode', yrange=[0, 4],\n",
    "    subplot_titles_=['<b>Daily<b>', '<b>Monthly<b>'],\n",
    "    title_='<b>Daily and Hourly Activity per Postcode<b>',\n",
    "    height_=750, width_=1000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
